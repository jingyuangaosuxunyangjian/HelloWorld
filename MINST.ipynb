{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78a0d12-1ea1-4445-a21a-874121cf19f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T04:54:11.004131Z",
     "iopub.status.busy": "2021-10-01T04:54:11.003593Z",
     "iopub.status.idle": "2021-10-01T04:54:14.385319Z",
     "shell.execute_reply": "2021-10-01T04:54:14.384482Z",
     "shell.execute_reply.started": "2021-10-01T04:54:11.003894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/image.py:425: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  a_min = np.asscalar(a_min.astype(scaled_dtype))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/image.py:426: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  a_max = np.asscalar(a_max.astype(scaled_dtype))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(1,) [5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndef train(model):\\n    model.train()\\n    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode=\\'train\\'),\\n    \\t\\t\\t\\t\\t\\t\\t\\t\\tbatch_size=16,\\n                                        shuffle=True)\\n    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\\n    EPOCH_NUM = 10\\n    for epoch in range(EPOCH_NUM):\\n        for batch_id, data in enumerate(train_loader()):\\n            images = norm_img(data[0]).astype(\\'float32\\')\\n            labels = data[1].astype(\\'float32\\')\\n\\n            predicts = model(images)\\n\\n            loss = F.square_error_cost(predicts, labels)\\n            avg_loss = paddle.mean(loss)\\n\\n            if batch_id % 1000 == 0:\\n                print(\"epoch_id: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\\n\\n            avg_loss.backward()\\n            opt.step()\\n            opt.clear_grad()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F \n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "train_dataset = paddle.vision.MNIST(mode='train')\n",
    "\n",
    "train_data0 = np.array(train_dataset[0][0])\n",
    "train_label_0 = np.array(train_dataset[0][1])\n",
    "plt.figure(\"image\")\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(train_data0, cmap=plt.cm.binary)\n",
    "plt.axis('on')\n",
    "plt.title('image')\n",
    "plt.show()\n",
    "\n",
    "print(train_data0.shape)\n",
    "print(train_label_0.shape, train_label_0)\n",
    "\n",
    "class MINST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MINST, self).__init__()\n",
    "\n",
    "        self.fc = paddle.nn.Linear(in_features=784, out_features=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.fc(inputs)\n",
    "        return outputs\n",
    "\n",
    "def norm_img(img):\n",
    "    assert len(img.shape) == 3\n",
    "    batch_size, img_h, img_w = img.shape[0], img.shape[1], img.shape[2]\n",
    "    img = img / 255\n",
    "    img = paddle.reshape(img, [batch_size, img_h*img_w])\n",
    "    \n",
    "    return img\n",
    "\n",
    "paddle.vision.set_image_backend('cv2')\n",
    "model = MINST()\n",
    "\n",
    "'''\n",
    "def train(model):\n",
    "    model.train()\n",
    "    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'),\n",
    "    \t\t\t\t\t\t\t\t\tbatch_size=16,\n",
    "                                        shuffle=True)\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            images = norm_img(data[0]).astype('float32')\n",
    "            labels = data[1].astype('float32')\n",
    "\n",
    "            predicts = model(images)\n",
    "\n",
    "            loss = F.square_error_cost(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 1000 == 0:\n",
    "                print(\"epoch_id: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "'''\n",
    "\n",
    "#train(model)\n",
    "#paddle.save(model.state_dict(), './mnist.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8924008-ae1a-4029-afdd-88326a5cc287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T04:54:35.486021Z",
     "iopub.status.busy": "2021-10-01T04:54:35.485648Z",
     "iopub.status.idle": "2021-10-01T04:54:35.521849Z",
     "shell.execute_reply": "2021-10-01T04:54:35.521054Z",
     "shell.execute_reply.started": "2021-10-01T04:54:35.485972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result Tensor(shape=[1, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[5.75658274]])\n",
      "本次预测的数字是 [[5]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "\n",
    "def load_image(img_path):\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "    im = np.array(im).reshape(1, -1).astype(np.float32)\n",
    "    im = 1 - im / 255\n",
    "    return im\n",
    "\n",
    "model = MINST()\n",
    "params_file_path = 'mnist.pdparams'\n",
    "img_path = './test_3_2.jpg'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "result = model(paddle.to_tensor(tensor_img))\n",
    "print('result',result)\n",
    "print(\"本次预测的数字是\", result.numpy().astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8827c4c-00c2-4b5a-91e3-db1d62304847",
   "metadata": {},
   "source": [
    "上面的代码抄自PaddlePaddle的官方教程，注释我懒得写了，去官网找吧\n",
    "\n",
    "这种方式没有经过预处理，直接接入网络，效果实在感人，我写了四个数字，没有一个识别对的，下面分析一下原因。\n",
    "\n",
    "首先，这个问题并不是一个线性的问题，而我们的网络是一个单层的，也就是线性分类器，我们再用一个线性的东西去拟合一个非线性的，所以效果就会很不好。\n",
    "\n",
    "下面对解决方案提出一些解决方案的猜想\n",
    "- 进行预处理，让问题趋近于线性问题\n",
    "- 增加网络的复杂度，去拟合非线性的问题\n",
    "- 先提取特征再进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcaf0d7-c908-48d0-aebb-355cc926f77a",
   "metadata": {},
   "source": [
    "我们先尝试预处理的方案，这里需要在喂数据前进行预处理，我们对训练函数进行修改，并增加预处理函数before_train，需要opencv环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33759a94-77f9-48a1-a13b-6b5d2008f223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T04:54:41.701805Z",
     "iopub.status.busy": "2021-10-01T04:54:41.701420Z",
     "iopub.status.idle": "2021-10-01T05:10:09.641489Z",
     "shell.execute_reply": "2021-10-01T05:10:09.640662Z",
     "shell.execute_reply.started": "2021-10-01T04:54:41.701753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id: 0, batch_id: 0, loss is: [3.8233187]\n",
      "epoch_id: 0, batch_id: 1000, loss is: [4.464732]\n",
      "epoch_id: 0, batch_id: 2000, loss is: [9.15641]\n",
      "epoch_id: 0, batch_id: 3000, loss is: [13.675595]\n",
      "epoch_id: 0, batch_id: 4000, loss is: [3.2717824]\n",
      "epoch_id: 0, batch_id: 5000, loss is: [5.3499722]\n",
      "epoch_id: 0, batch_id: 6000, loss is: [0.4531188]\n",
      "epoch_id: 0, batch_id: 7000, loss is: [17.119446]\n",
      "epoch_id: 0, batch_id: 8000, loss is: [5.171847]\n",
      "epoch_id: 0, batch_id: 9000, loss is: [13.9322405]\n",
      "epoch_id: 0, batch_id: 10000, loss is: [8.630498]\n",
      "epoch_id: 0, batch_id: 11000, loss is: [10.47385]\n",
      "epoch_id: 0, batch_id: 12000, loss is: [16.082396]\n",
      "epoch_id: 0, batch_id: 13000, loss is: [2.9939675]\n",
      "epoch_id: 0, batch_id: 14000, loss is: [23.372213]\n",
      "epoch_id: 0, batch_id: 15000, loss is: [9.925264]\n",
      "epoch_id: 0, batch_id: 16000, loss is: [0.73140424]\n",
      "epoch_id: 0, batch_id: 17000, loss is: [3.57947]\n",
      "epoch_id: 0, batch_id: 18000, loss is: [3.5038922]\n",
      "epoch_id: 0, batch_id: 19000, loss is: [14.762081]\n",
      "epoch_id: 0, batch_id: 20000, loss is: [14.02901]\n",
      "epoch_id: 0, batch_id: 21000, loss is: [3.0992777]\n",
      "epoch_id: 0, batch_id: 22000, loss is: [9.782865]\n",
      "epoch_id: 0, batch_id: 23000, loss is: [5.75498]\n",
      "epoch_id: 0, batch_id: 24000, loss is: [16.797281]\n",
      "epoch_id: 0, batch_id: 25000, loss is: [3.525993]\n",
      "epoch_id: 0, batch_id: 26000, loss is: [4.2965755]\n",
      "epoch_id: 0, batch_id: 27000, loss is: [9.207737]\n",
      "epoch_id: 0, batch_id: 28000, loss is: [0.00292826]\n",
      "epoch_id: 0, batch_id: 29000, loss is: [0.0008472]\n",
      "epoch_id: 0, batch_id: 30000, loss is: [24.212524]\n",
      "epoch_id: 0, batch_id: 31000, loss is: [4.272244]\n",
      "epoch_id: 0, batch_id: 32000, loss is: [4.11822]\n",
      "epoch_id: 0, batch_id: 33000, loss is: [9.30671]\n",
      "epoch_id: 0, batch_id: 34000, loss is: [17.65126]\n",
      "epoch_id: 0, batch_id: 35000, loss is: [0.92982143]\n",
      "epoch_id: 0, batch_id: 36000, loss is: [0.5723994]\n",
      "epoch_id: 0, batch_id: 37000, loss is: [10.239767]\n",
      "epoch_id: 0, batch_id: 38000, loss is: [5.953379]\n",
      "epoch_id: 0, batch_id: 39000, loss is: [3.8528516]\n",
      "epoch_id: 0, batch_id: 40000, loss is: [3.5249152]\n",
      "epoch_id: 0, batch_id: 41000, loss is: [17.726309]\n",
      "epoch_id: 0, batch_id: 42000, loss is: [4.634086]\n",
      "epoch_id: 0, batch_id: 43000, loss is: [1.1041383]\n",
      "epoch_id: 0, batch_id: 44000, loss is: [8.45721]\n",
      "epoch_id: 0, batch_id: 45000, loss is: [10.333075]\n",
      "epoch_id: 0, batch_id: 46000, loss is: [1.3347173]\n",
      "epoch_id: 0, batch_id: 47000, loss is: [0.7506783]\n",
      "epoch_id: 0, batch_id: 48000, loss is: [0.00469768]\n",
      "epoch_id: 0, batch_id: 49000, loss is: [8.138002]\n",
      "epoch_id: 0, batch_id: 50000, loss is: [3.8174787]\n",
      "epoch_id: 0, batch_id: 51000, loss is: [1.9310936]\n",
      "epoch_id: 0, batch_id: 52000, loss is: [0.04927347]\n",
      "epoch_id: 0, batch_id: 53000, loss is: [16.313387]\n",
      "epoch_id: 0, batch_id: 54000, loss is: [17.876787]\n",
      "epoch_id: 0, batch_id: 55000, loss is: [24.191294]\n",
      "epoch_id: 0, batch_id: 56000, loss is: [23.860735]\n",
      "epoch_id: 0, batch_id: 57000, loss is: [23.20245]\n",
      "epoch_id: 0, batch_id: 58000, loss is: [10.702389]\n",
      "epoch_id: 0, batch_id: 59000, loss is: [10.42958]\n",
      "epoch_id: 1, batch_id: 0, loss is: [7.795737]\n",
      "epoch_id: 1, batch_id: 1000, loss is: [3.284686]\n",
      "epoch_id: 1, batch_id: 2000, loss is: [5.037944]\n",
      "epoch_id: 1, batch_id: 3000, loss is: [0.01095692]\n",
      "epoch_id: 1, batch_id: 4000, loss is: [1.0061377]\n",
      "epoch_id: 1, batch_id: 5000, loss is: [6.939256]\n",
      "epoch_id: 1, batch_id: 6000, loss is: [3.667475]\n",
      "epoch_id: 1, batch_id: 7000, loss is: [14.816713]\n",
      "epoch_id: 1, batch_id: 8000, loss is: [3.3790042]\n",
      "epoch_id: 1, batch_id: 9000, loss is: [0.9686806]\n",
      "epoch_id: 1, batch_id: 10000, loss is: [1.0173812]\n",
      "epoch_id: 1, batch_id: 11000, loss is: [3.5932245]\n",
      "epoch_id: 1, batch_id: 12000, loss is: [3.2652082]\n",
      "epoch_id: 1, batch_id: 13000, loss is: [3.6456935]\n",
      "epoch_id: 1, batch_id: 14000, loss is: [17.866589]\n",
      "epoch_id: 1, batch_id: 15000, loss is: [9.825518]\n",
      "epoch_id: 1, batch_id: 16000, loss is: [10.789082]\n",
      "epoch_id: 1, batch_id: 17000, loss is: [0.02709846]\n",
      "epoch_id: 1, batch_id: 18000, loss is: [14.864397]\n",
      "epoch_id: 1, batch_id: 19000, loss is: [13.792753]\n",
      "epoch_id: 1, batch_id: 20000, loss is: [0.6004426]\n",
      "epoch_id: 1, batch_id: 21000, loss is: [9.769613]\n",
      "epoch_id: 1, batch_id: 22000, loss is: [9.315348]\n",
      "epoch_id: 1, batch_id: 23000, loss is: [0.07910478]\n",
      "epoch_id: 1, batch_id: 24000, loss is: [10.542822]\n",
      "epoch_id: 1, batch_id: 25000, loss is: [0.01461938]\n",
      "epoch_id: 1, batch_id: 26000, loss is: [17.876856]\n",
      "epoch_id: 1, batch_id: 27000, loss is: [10.100857]\n",
      "epoch_id: 1, batch_id: 28000, loss is: [0.07108097]\n",
      "epoch_id: 1, batch_id: 29000, loss is: [4.5992494]\n",
      "epoch_id: 1, batch_id: 30000, loss is: [14.607444]\n",
      "epoch_id: 1, batch_id: 31000, loss is: [5.0568795]\n",
      "epoch_id: 1, batch_id: 32000, loss is: [22.50109]\n",
      "epoch_id: 1, batch_id: 33000, loss is: [0.00649463]\n",
      "epoch_id: 1, batch_id: 34000, loss is: [15.74144]\n",
      "epoch_id: 1, batch_id: 35000, loss is: [1.0949212]\n",
      "epoch_id: 1, batch_id: 36000, loss is: [17.544582]\n",
      "epoch_id: 1, batch_id: 37000, loss is: [0.75142545]\n",
      "epoch_id: 1, batch_id: 38000, loss is: [0.7476332]\n",
      "epoch_id: 1, batch_id: 39000, loss is: [0.02775023]\n",
      "epoch_id: 1, batch_id: 40000, loss is: [0.00894424]\n",
      "epoch_id: 1, batch_id: 41000, loss is: [0.28701928]\n",
      "epoch_id: 1, batch_id: 42000, loss is: [7.9780025]\n",
      "epoch_id: 1, batch_id: 43000, loss is: [0.7187135]\n",
      "epoch_id: 1, batch_id: 44000, loss is: [3.5174618]\n",
      "epoch_id: 1, batch_id: 45000, loss is: [16.055796]\n",
      "epoch_id: 1, batch_id: 46000, loss is: [7.4988213]\n",
      "epoch_id: 1, batch_id: 47000, loss is: [0.62006825]\n",
      "epoch_id: 1, batch_id: 48000, loss is: [3.1033473]\n",
      "epoch_id: 1, batch_id: 49000, loss is: [8.169403]\n",
      "epoch_id: 1, batch_id: 50000, loss is: [16.931183]\n",
      "epoch_id: 1, batch_id: 51000, loss is: [10.498133]\n",
      "epoch_id: 1, batch_id: 52000, loss is: [17.358444]\n",
      "epoch_id: 1, batch_id: 53000, loss is: [4.672583]\n",
      "epoch_id: 1, batch_id: 54000, loss is: [0.58050823]\n",
      "epoch_id: 1, batch_id: 55000, loss is: [0.66340226]\n",
      "epoch_id: 1, batch_id: 56000, loss is: [0.8440381]\n",
      "epoch_id: 1, batch_id: 57000, loss is: [7.983615]\n",
      "epoch_id: 1, batch_id: 58000, loss is: [0.74609697]\n",
      "epoch_id: 1, batch_id: 59000, loss is: [0.7835867]\n",
      "epoch_id: 2, batch_id: 0, loss is: [9.938152]\n",
      "epoch_id: 2, batch_id: 1000, loss is: [0.02531875]\n",
      "epoch_id: 2, batch_id: 2000, loss is: [0.00732734]\n",
      "epoch_id: 2, batch_id: 3000, loss is: [14.5994005]\n",
      "epoch_id: 2, batch_id: 4000, loss is: [1.6490085]\n",
      "epoch_id: 2, batch_id: 5000, loss is: [15.033365]\n",
      "epoch_id: 2, batch_id: 6000, loss is: [9.973756]\n",
      "epoch_id: 2, batch_id: 7000, loss is: [9.738212]\n",
      "epoch_id: 2, batch_id: 8000, loss is: [3.2705078]\n",
      "epoch_id: 2, batch_id: 9000, loss is: [3.1624825]\n",
      "epoch_id: 2, batch_id: 10000, loss is: [1.2483135]\n",
      "epoch_id: 2, batch_id: 11000, loss is: [23.845806]\n",
      "epoch_id: 2, batch_id: 12000, loss is: [23.76608]\n",
      "epoch_id: 2, batch_id: 13000, loss is: [0.07005192]\n",
      "epoch_id: 2, batch_id: 14000, loss is: [0.04560873]\n",
      "epoch_id: 2, batch_id: 15000, loss is: [1.5554805]\n",
      "epoch_id: 2, batch_id: 16000, loss is: [3.4884906]\n",
      "epoch_id: 2, batch_id: 17000, loss is: [10.895094]\n",
      "epoch_id: 2, batch_id: 18000, loss is: [4.657606]\n",
      "epoch_id: 2, batch_id: 19000, loss is: [3.577848]\n",
      "epoch_id: 2, batch_id: 20000, loss is: [0.4756869]\n",
      "epoch_id: 2, batch_id: 21000, loss is: [4.5121036]\n",
      "epoch_id: 2, batch_id: 22000, loss is: [17.909533]\n",
      "epoch_id: 2, batch_id: 23000, loss is: [0.00012325]\n",
      "epoch_id: 2, batch_id: 24000, loss is: [7.112542]\n",
      "epoch_id: 2, batch_id: 25000, loss is: [0.08329599]\n",
      "epoch_id: 2, batch_id: 26000, loss is: [16.085567]\n",
      "epoch_id: 2, batch_id: 27000, loss is: [25.119556]\n",
      "epoch_id: 2, batch_id: 28000, loss is: [8.988535]\n",
      "epoch_id: 2, batch_id: 29000, loss is: [23.697294]\n",
      "epoch_id: 2, batch_id: 30000, loss is: [1.2850494]\n",
      "epoch_id: 2, batch_id: 31000, loss is: [0.03296024]\n",
      "epoch_id: 2, batch_id: 32000, loss is: [24.647055]\n",
      "epoch_id: 2, batch_id: 33000, loss is: [0.6792658]\n",
      "epoch_id: 2, batch_id: 34000, loss is: [10.340552]\n",
      "epoch_id: 2, batch_id: 35000, loss is: [9.9734335]\n",
      "epoch_id: 2, batch_id: 36000, loss is: [0.00439543]\n",
      "epoch_id: 2, batch_id: 37000, loss is: [8.455912]\n",
      "epoch_id: 2, batch_id: 38000, loss is: [16.786945]\n",
      "epoch_id: 2, batch_id: 39000, loss is: [3.539469]\n",
      "epoch_id: 2, batch_id: 40000, loss is: [17.276844]\n",
      "epoch_id: 2, batch_id: 41000, loss is: [1.5635003]\n",
      "epoch_id: 2, batch_id: 42000, loss is: [7.9288945]\n",
      "epoch_id: 2, batch_id: 43000, loss is: [0.04809574]\n",
      "epoch_id: 2, batch_id: 44000, loss is: [7.3285913]\n",
      "epoch_id: 2, batch_id: 45000, loss is: [10.239864]\n",
      "epoch_id: 2, batch_id: 46000, loss is: [0.8359252]\n",
      "epoch_id: 2, batch_id: 47000, loss is: [24.150639]\n",
      "epoch_id: 2, batch_id: 48000, loss is: [0.01376568]\n",
      "epoch_id: 2, batch_id: 49000, loss is: [10.757582]\n",
      "epoch_id: 2, batch_id: 50000, loss is: [18.956528]\n",
      "epoch_id: 2, batch_id: 51000, loss is: [9.8788]\n",
      "epoch_id: 2, batch_id: 52000, loss is: [16.0523]\n",
      "epoch_id: 2, batch_id: 53000, loss is: [17.610027]\n",
      "epoch_id: 2, batch_id: 54000, loss is: [14.282862]\n",
      "epoch_id: 2, batch_id: 55000, loss is: [14.525766]\n",
      "epoch_id: 2, batch_id: 56000, loss is: [4.130098]\n",
      "epoch_id: 2, batch_id: 57000, loss is: [24.088114]\n",
      "epoch_id: 2, batch_id: 58000, loss is: [9.867905]\n",
      "epoch_id: 2, batch_id: 59000, loss is: [16.563492]\n",
      "epoch_id: 3, batch_id: 0, loss is: [1.2204065]\n",
      "epoch_id: 3, batch_id: 1000, loss is: [15.10917]\n",
      "epoch_id: 3, batch_id: 2000, loss is: [1.3201389]\n",
      "epoch_id: 3, batch_id: 3000, loss is: [4.54321]\n",
      "epoch_id: 3, batch_id: 4000, loss is: [16.761131]\n",
      "epoch_id: 3, batch_id: 5000, loss is: [16.867676]\n",
      "epoch_id: 3, batch_id: 6000, loss is: [4.844721]\n",
      "epoch_id: 3, batch_id: 7000, loss is: [17.146477]\n",
      "epoch_id: 3, batch_id: 8000, loss is: [4.9633327]\n",
      "epoch_id: 3, batch_id: 9000, loss is: [9.672724]\n",
      "epoch_id: 3, batch_id: 10000, loss is: [9.261656]\n",
      "epoch_id: 3, batch_id: 11000, loss is: [4.240471]\n",
      "epoch_id: 3, batch_id: 12000, loss is: [3.801471]\n",
      "epoch_id: 3, batch_id: 13000, loss is: [16.175577]\n",
      "epoch_id: 3, batch_id: 14000, loss is: [3.3091505]\n",
      "epoch_id: 3, batch_id: 15000, loss is: [4.4490466]\n",
      "epoch_id: 3, batch_id: 16000, loss is: [4.702884]\n",
      "epoch_id: 3, batch_id: 17000, loss is: [10.122498]\n",
      "epoch_id: 3, batch_id: 18000, loss is: [0.8359845]\n",
      "epoch_id: 3, batch_id: 19000, loss is: [15.516045]\n",
      "epoch_id: 3, batch_id: 20000, loss is: [0.06604874]\n",
      "epoch_id: 3, batch_id: 21000, loss is: [11.327146]\n",
      "epoch_id: 3, batch_id: 22000, loss is: [17.033895]\n",
      "epoch_id: 3, batch_id: 23000, loss is: [1.1459445]\n",
      "epoch_id: 3, batch_id: 24000, loss is: [23.560757]\n",
      "epoch_id: 3, batch_id: 25000, loss is: [14.405829]\n",
      "epoch_id: 3, batch_id: 26000, loss is: [9.786023]\n",
      "epoch_id: 3, batch_id: 27000, loss is: [1.3939012]\n",
      "epoch_id: 3, batch_id: 28000, loss is: [14.134446]\n",
      "epoch_id: 3, batch_id: 29000, loss is: [23.93233]\n",
      "epoch_id: 3, batch_id: 30000, loss is: [15.390968]\n",
      "epoch_id: 3, batch_id: 31000, loss is: [8.012424]\n",
      "epoch_id: 3, batch_id: 32000, loss is: [8.031671]\n",
      "epoch_id: 3, batch_id: 33000, loss is: [0.84505916]\n",
      "epoch_id: 3, batch_id: 34000, loss is: [0.08747407]\n",
      "epoch_id: 3, batch_id: 35000, loss is: [14.476441]\n",
      "epoch_id: 3, batch_id: 36000, loss is: [0.3901078]\n",
      "epoch_id: 3, batch_id: 37000, loss is: [11.021112]\n",
      "epoch_id: 3, batch_id: 38000, loss is: [16.99131]\n",
      "epoch_id: 3, batch_id: 39000, loss is: [24.009945]\n",
      "epoch_id: 3, batch_id: 40000, loss is: [14.099049]\n",
      "epoch_id: 3, batch_id: 41000, loss is: [0.934415]\n",
      "epoch_id: 3, batch_id: 42000, loss is: [9.4063015]\n",
      "epoch_id: 3, batch_id: 43000, loss is: [16.944622]\n",
      "epoch_id: 3, batch_id: 44000, loss is: [0.81573135]\n",
      "epoch_id: 3, batch_id: 45000, loss is: [16.483797]\n",
      "epoch_id: 3, batch_id: 46000, loss is: [0.6639958]\n",
      "epoch_id: 3, batch_id: 47000, loss is: [3.436328]\n",
      "epoch_id: 3, batch_id: 48000, loss is: [17.220392]\n",
      "epoch_id: 3, batch_id: 49000, loss is: [14.803369]\n",
      "epoch_id: 3, batch_id: 50000, loss is: [9.811114]\n",
      "epoch_id: 3, batch_id: 51000, loss is: [0.38159347]\n",
      "epoch_id: 3, batch_id: 52000, loss is: [5.190181]\n",
      "epoch_id: 3, batch_id: 53000, loss is: [1.402345]\n",
      "epoch_id: 3, batch_id: 54000, loss is: [13.877674]\n",
      "epoch_id: 3, batch_id: 55000, loss is: [4.3397837]\n",
      "epoch_id: 3, batch_id: 56000, loss is: [24.606747]\n",
      "epoch_id: 3, batch_id: 57000, loss is: [9.394746]\n",
      "epoch_id: 3, batch_id: 58000, loss is: [9.40875]\n",
      "epoch_id: 3, batch_id: 59000, loss is: [0.0133365]\n",
      "epoch_id: 4, batch_id: 0, loss is: [16.39803]\n",
      "epoch_id: 4, batch_id: 1000, loss is: [0.8353847]\n",
      "epoch_id: 4, batch_id: 2000, loss is: [15.372794]\n",
      "epoch_id: 4, batch_id: 3000, loss is: [4.679574]\n",
      "epoch_id: 4, batch_id: 4000, loss is: [1.0768217]\n",
      "epoch_id: 4, batch_id: 5000, loss is: [8.264572]\n",
      "epoch_id: 4, batch_id: 6000, loss is: [17.414835]\n",
      "epoch_id: 4, batch_id: 7000, loss is: [3.1100912]\n",
      "epoch_id: 4, batch_id: 8000, loss is: [22.24653]\n",
      "epoch_id: 4, batch_id: 9000, loss is: [9.959467]\n",
      "epoch_id: 4, batch_id: 10000, loss is: [0.04374006]\n",
      "epoch_id: 4, batch_id: 11000, loss is: [25.009968]\n",
      "epoch_id: 4, batch_id: 12000, loss is: [1.108839]\n",
      "epoch_id: 4, batch_id: 13000, loss is: [7.0961924]\n",
      "epoch_id: 4, batch_id: 14000, loss is: [9.697212]\n",
      "epoch_id: 4, batch_id: 15000, loss is: [7.61663]\n",
      "epoch_id: 4, batch_id: 16000, loss is: [4.897689]\n",
      "epoch_id: 4, batch_id: 17000, loss is: [9.49382]\n",
      "epoch_id: 4, batch_id: 18000, loss is: [9.7725315]\n",
      "epoch_id: 4, batch_id: 19000, loss is: [10.243386]\n",
      "epoch_id: 4, batch_id: 20000, loss is: [10.395532]\n",
      "epoch_id: 4, batch_id: 21000, loss is: [23.939192]\n",
      "epoch_id: 4, batch_id: 22000, loss is: [0.6923871]\n",
      "epoch_id: 4, batch_id: 23000, loss is: [3.941049]\n",
      "epoch_id: 4, batch_id: 24000, loss is: [23.05499]\n",
      "epoch_id: 4, batch_id: 25000, loss is: [4.1679816]\n",
      "epoch_id: 4, batch_id: 26000, loss is: [0.02470805]\n",
      "epoch_id: 4, batch_id: 27000, loss is: [9.354987]\n",
      "epoch_id: 4, batch_id: 28000, loss is: [0.84686255]\n",
      "epoch_id: 4, batch_id: 29000, loss is: [9.567737]\n",
      "epoch_id: 4, batch_id: 30000, loss is: [0.6407039]\n",
      "epoch_id: 4, batch_id: 31000, loss is: [0.03662138]\n",
      "epoch_id: 4, batch_id: 32000, loss is: [1.7016371]\n",
      "epoch_id: 4, batch_id: 33000, loss is: [4.6675544]\n",
      "epoch_id: 4, batch_id: 34000, loss is: [3.514158]\n",
      "epoch_id: 4, batch_id: 35000, loss is: [16.600677]\n",
      "epoch_id: 4, batch_id: 36000, loss is: [3.2955668]\n",
      "epoch_id: 4, batch_id: 37000, loss is: [5.3673925]\n",
      "epoch_id: 4, batch_id: 38000, loss is: [1.9208894]\n",
      "epoch_id: 4, batch_id: 39000, loss is: [3.7808855]\n",
      "epoch_id: 4, batch_id: 40000, loss is: [1.4111043]\n",
      "epoch_id: 4, batch_id: 41000, loss is: [1.2613971]\n",
      "epoch_id: 4, batch_id: 42000, loss is: [0.73892456]\n",
      "epoch_id: 4, batch_id: 43000, loss is: [0.87847626]\n",
      "epoch_id: 4, batch_id: 44000, loss is: [5.505104]\n",
      "epoch_id: 4, batch_id: 45000, loss is: [14.75082]\n",
      "epoch_id: 4, batch_id: 46000, loss is: [14.315264]\n",
      "epoch_id: 4, batch_id: 47000, loss is: [18.356161]\n",
      "epoch_id: 4, batch_id: 48000, loss is: [23.550056]\n",
      "epoch_id: 4, batch_id: 49000, loss is: [10.08149]\n",
      "epoch_id: 4, batch_id: 50000, loss is: [0.46176252]\n",
      "epoch_id: 4, batch_id: 51000, loss is: [0.6964616]\n",
      "epoch_id: 4, batch_id: 52000, loss is: [0.05433691]\n",
      "epoch_id: 4, batch_id: 53000, loss is: [18.310223]\n",
      "epoch_id: 4, batch_id: 54000, loss is: [4.9380283]\n",
      "epoch_id: 4, batch_id: 55000, loss is: [1.1294414]\n",
      "epoch_id: 4, batch_id: 56000, loss is: [24.385004]\n",
      "epoch_id: 4, batch_id: 57000, loss is: [1.4563293]\n",
      "epoch_id: 4, batch_id: 58000, loss is: [17.515629]\n",
      "epoch_id: 4, batch_id: 59000, loss is: [0.0237662]\n",
      "epoch_id: 5, batch_id: 0, loss is: [13.84744]\n",
      "epoch_id: 5, batch_id: 1000, loss is: [0.7494708]\n",
      "epoch_id: 5, batch_id: 2000, loss is: [4.690023]\n",
      "epoch_id: 5, batch_id: 3000, loss is: [0.4618325]\n",
      "epoch_id: 5, batch_id: 4000, loss is: [18.153336]\n",
      "epoch_id: 5, batch_id: 5000, loss is: [3.387189]\n",
      "epoch_id: 5, batch_id: 6000, loss is: [23.846432]\n",
      "epoch_id: 5, batch_id: 7000, loss is: [1.2362704]\n",
      "epoch_id: 5, batch_id: 8000, loss is: [10.0953045]\n",
      "epoch_id: 5, batch_id: 9000, loss is: [23.60605]\n",
      "epoch_id: 5, batch_id: 10000, loss is: [0.03093376]\n",
      "epoch_id: 5, batch_id: 11000, loss is: [14.489097]\n",
      "epoch_id: 5, batch_id: 12000, loss is: [0.03238174]\n",
      "epoch_id: 5, batch_id: 13000, loss is: [4.446816]\n",
      "epoch_id: 5, batch_id: 14000, loss is: [0.90873545]\n",
      "epoch_id: 5, batch_id: 15000, loss is: [0.02213602]\n",
      "epoch_id: 5, batch_id: 16000, loss is: [1.2587775]\n",
      "epoch_id: 5, batch_id: 17000, loss is: [1.3659248e-06]\n",
      "epoch_id: 5, batch_id: 18000, loss is: [0.58062595]\n",
      "epoch_id: 5, batch_id: 19000, loss is: [5.1280537]\n",
      "epoch_id: 5, batch_id: 20000, loss is: [17.42075]\n",
      "epoch_id: 5, batch_id: 21000, loss is: [0.00082223]\n",
      "epoch_id: 5, batch_id: 22000, loss is: [0.6585633]\n",
      "epoch_id: 5, batch_id: 23000, loss is: [3.6222198]\n",
      "epoch_id: 5, batch_id: 24000, loss is: [1.1710888]\n",
      "epoch_id: 5, batch_id: 25000, loss is: [17.375168]\n",
      "epoch_id: 5, batch_id: 26000, loss is: [0.85853714]\n",
      "epoch_id: 5, batch_id: 27000, loss is: [4.4083133]\n",
      "epoch_id: 5, batch_id: 28000, loss is: [17.630518]\n",
      "epoch_id: 5, batch_id: 29000, loss is: [14.390638]\n",
      "epoch_id: 5, batch_id: 30000, loss is: [13.350997]\n",
      "epoch_id: 5, batch_id: 31000, loss is: [3.313088]\n",
      "epoch_id: 5, batch_id: 32000, loss is: [1.2936997]\n",
      "epoch_id: 5, batch_id: 33000, loss is: [0.6264226]\n",
      "epoch_id: 5, batch_id: 34000, loss is: [14.210114]\n",
      "epoch_id: 5, batch_id: 35000, loss is: [9.552651]\n",
      "epoch_id: 5, batch_id: 36000, loss is: [0.02401117]\n",
      "epoch_id: 5, batch_id: 37000, loss is: [0.0191868]\n",
      "epoch_id: 5, batch_id: 38000, loss is: [17.794657]\n",
      "epoch_id: 5, batch_id: 39000, loss is: [17.263456]\n",
      "epoch_id: 5, batch_id: 40000, loss is: [4.442843]\n",
      "epoch_id: 5, batch_id: 41000, loss is: [10.287821]\n",
      "epoch_id: 5, batch_id: 42000, loss is: [4.85152]\n",
      "epoch_id: 5, batch_id: 43000, loss is: [1.1506873]\n",
      "epoch_id: 5, batch_id: 44000, loss is: [8.92353]\n",
      "epoch_id: 5, batch_id: 45000, loss is: [3.3383477]\n",
      "epoch_id: 5, batch_id: 46000, loss is: [0.00925499]\n",
      "epoch_id: 5, batch_id: 47000, loss is: [12.816177]\n",
      "epoch_id: 5, batch_id: 48000, loss is: [4.3987136]\n",
      "epoch_id: 5, batch_id: 49000, loss is: [3.2021933]\n",
      "epoch_id: 5, batch_id: 50000, loss is: [23.909645]\n",
      "epoch_id: 5, batch_id: 51000, loss is: [3.0494695]\n",
      "epoch_id: 5, batch_id: 52000, loss is: [0.8337268]\n",
      "epoch_id: 5, batch_id: 53000, loss is: [1.3351657]\n",
      "epoch_id: 5, batch_id: 54000, loss is: [17.146627]\n",
      "epoch_id: 5, batch_id: 55000, loss is: [9.697402]\n",
      "epoch_id: 5, batch_id: 56000, loss is: [9.367423]\n",
      "epoch_id: 5, batch_id: 57000, loss is: [1.1296724]\n",
      "epoch_id: 5, batch_id: 58000, loss is: [0.01994864]\n",
      "epoch_id: 5, batch_id: 59000, loss is: [4.4433136]\n",
      "epoch_id: 6, batch_id: 0, loss is: [1.3676174]\n",
      "epoch_id: 6, batch_id: 1000, loss is: [21.501442]\n",
      "epoch_id: 6, batch_id: 2000, loss is: [23.03033]\n",
      "epoch_id: 6, batch_id: 3000, loss is: [10.215813]\n",
      "epoch_id: 6, batch_id: 4000, loss is: [9.275822]\n",
      "epoch_id: 6, batch_id: 5000, loss is: [0.03101415]\n",
      "epoch_id: 6, batch_id: 6000, loss is: [2.7999387]\n",
      "epoch_id: 6, batch_id: 7000, loss is: [3.2139914]\n",
      "epoch_id: 6, batch_id: 8000, loss is: [10.004938]\n",
      "epoch_id: 6, batch_id: 9000, loss is: [0.10028408]\n",
      "epoch_id: 6, batch_id: 10000, loss is: [3.5466638]\n",
      "epoch_id: 6, batch_id: 11000, loss is: [8.30023]\n",
      "epoch_id: 6, batch_id: 12000, loss is: [1.3894292]\n",
      "epoch_id: 6, batch_id: 13000, loss is: [1.1884038]\n",
      "epoch_id: 6, batch_id: 14000, loss is: [4.50179]\n",
      "epoch_id: 6, batch_id: 15000, loss is: [3.6897318]\n",
      "epoch_id: 6, batch_id: 16000, loss is: [0.9554768]\n",
      "epoch_id: 6, batch_id: 17000, loss is: [7.3368526]\n",
      "epoch_id: 6, batch_id: 18000, loss is: [4.6209855]\n",
      "epoch_id: 6, batch_id: 19000, loss is: [10.125346]\n",
      "epoch_id: 6, batch_id: 20000, loss is: [3.3842723]\n",
      "epoch_id: 6, batch_id: 21000, loss is: [15.041631]\n",
      "epoch_id: 6, batch_id: 22000, loss is: [9.999219]\n",
      "epoch_id: 6, batch_id: 23000, loss is: [1.4181709]\n",
      "epoch_id: 6, batch_id: 24000, loss is: [0.68792105]\n",
      "epoch_id: 6, batch_id: 25000, loss is: [10.561809]\n",
      "epoch_id: 6, batch_id: 26000, loss is: [0.02079126]\n",
      "epoch_id: 6, batch_id: 27000, loss is: [18.513084]\n",
      "epoch_id: 6, batch_id: 28000, loss is: [3.2750883]\n",
      "epoch_id: 6, batch_id: 29000, loss is: [24.451828]\n",
      "epoch_id: 6, batch_id: 30000, loss is: [0.7265383]\n",
      "epoch_id: 6, batch_id: 31000, loss is: [0.0866392]\n",
      "epoch_id: 6, batch_id: 32000, loss is: [3.8678932]\n",
      "epoch_id: 6, batch_id: 33000, loss is: [4.752507]\n",
      "epoch_id: 6, batch_id: 34000, loss is: [23.199093]\n",
      "epoch_id: 6, batch_id: 35000, loss is: [23.360588]\n",
      "epoch_id: 6, batch_id: 36000, loss is: [1.3609183]\n",
      "epoch_id: 6, batch_id: 37000, loss is: [1.1015253]\n",
      "epoch_id: 6, batch_id: 38000, loss is: [0.56137186]\n",
      "epoch_id: 6, batch_id: 39000, loss is: [1.463094]\n",
      "epoch_id: 6, batch_id: 40000, loss is: [0.5586464]\n",
      "epoch_id: 6, batch_id: 41000, loss is: [23.869429]\n",
      "epoch_id: 6, batch_id: 42000, loss is: [4.982064]\n",
      "epoch_id: 6, batch_id: 43000, loss is: [23.052309]\n",
      "epoch_id: 6, batch_id: 44000, loss is: [4.323516]\n",
      "epoch_id: 6, batch_id: 45000, loss is: [16.188925]\n",
      "epoch_id: 6, batch_id: 46000, loss is: [1.2562654]\n",
      "epoch_id: 6, batch_id: 47000, loss is: [17.597586]\n",
      "epoch_id: 6, batch_id: 48000, loss is: [15.596091]\n",
      "epoch_id: 6, batch_id: 49000, loss is: [0.9020367]\n",
      "epoch_id: 6, batch_id: 50000, loss is: [0.6724433]\n",
      "epoch_id: 6, batch_id: 51000, loss is: [1.3638971]\n",
      "epoch_id: 6, batch_id: 52000, loss is: [8.222779]\n",
      "epoch_id: 6, batch_id: 53000, loss is: [3.712969]\n",
      "epoch_id: 6, batch_id: 54000, loss is: [0.05491063]\n",
      "epoch_id: 6, batch_id: 55000, loss is: [3.7524004]\n",
      "epoch_id: 6, batch_id: 56000, loss is: [17.22169]\n",
      "epoch_id: 6, batch_id: 57000, loss is: [0.03664877]\n",
      "epoch_id: 6, batch_id: 58000, loss is: [9.991314]\n",
      "epoch_id: 6, batch_id: 59000, loss is: [15.396723]\n",
      "epoch_id: 7, batch_id: 0, loss is: [3.7145312]\n",
      "epoch_id: 7, batch_id: 1000, loss is: [9.863184]\n",
      "epoch_id: 7, batch_id: 2000, loss is: [15.073126]\n",
      "epoch_id: 7, batch_id: 3000, loss is: [1.4703739]\n",
      "epoch_id: 7, batch_id: 4000, loss is: [0.62434936]\n",
      "epoch_id: 7, batch_id: 5000, loss is: [9.298543]\n",
      "epoch_id: 7, batch_id: 6000, loss is: [4.6457896]\n",
      "epoch_id: 7, batch_id: 7000, loss is: [1.3975787]\n",
      "epoch_id: 7, batch_id: 8000, loss is: [24.884666]\n",
      "epoch_id: 7, batch_id: 9000, loss is: [4.351163]\n",
      "epoch_id: 7, batch_id: 10000, loss is: [0.00210185]\n",
      "epoch_id: 7, batch_id: 11000, loss is: [24.242134]\n",
      "epoch_id: 7, batch_id: 12000, loss is: [0.07308834]\n",
      "epoch_id: 7, batch_id: 13000, loss is: [4.790859]\n",
      "epoch_id: 7, batch_id: 14000, loss is: [9.348425]\n",
      "epoch_id: 7, batch_id: 15000, loss is: [25.246367]\n",
      "epoch_id: 7, batch_id: 16000, loss is: [17.077234]\n",
      "epoch_id: 7, batch_id: 17000, loss is: [0.6696543]\n",
      "epoch_id: 7, batch_id: 18000, loss is: [0.23208538]\n",
      "epoch_id: 7, batch_id: 19000, loss is: [3.2354739]\n",
      "epoch_id: 7, batch_id: 20000, loss is: [3.5367548]\n",
      "epoch_id: 7, batch_id: 21000, loss is: [0.98735917]\n",
      "epoch_id: 7, batch_id: 22000, loss is: [3.7766716]\n",
      "epoch_id: 7, batch_id: 23000, loss is: [0.95984215]\n",
      "epoch_id: 7, batch_id: 24000, loss is: [10.179733]\n",
      "epoch_id: 7, batch_id: 25000, loss is: [4.3517995]\n",
      "epoch_id: 7, batch_id: 26000, loss is: [1.5977513]\n",
      "epoch_id: 7, batch_id: 27000, loss is: [3.0763695]\n",
      "epoch_id: 7, batch_id: 28000, loss is: [22.46013]\n",
      "epoch_id: 7, batch_id: 29000, loss is: [6.1106315]\n",
      "epoch_id: 7, batch_id: 30000, loss is: [13.606755]\n",
      "epoch_id: 7, batch_id: 31000, loss is: [8.121907]\n",
      "epoch_id: 7, batch_id: 32000, loss is: [0.57315797]\n",
      "epoch_id: 7, batch_id: 33000, loss is: [1.7276591]\n",
      "epoch_id: 7, batch_id: 34000, loss is: [3.9554148]\n",
      "epoch_id: 7, batch_id: 35000, loss is: [15.750318]\n",
      "epoch_id: 7, batch_id: 36000, loss is: [16.625343]\n",
      "epoch_id: 7, batch_id: 37000, loss is: [0.01906125]\n",
      "epoch_id: 7, batch_id: 38000, loss is: [3.3079414]\n",
      "epoch_id: 7, batch_id: 39000, loss is: [10.122519]\n",
      "epoch_id: 7, batch_id: 40000, loss is: [1.3142252]\n",
      "epoch_id: 7, batch_id: 41000, loss is: [7.9383636]\n",
      "epoch_id: 7, batch_id: 42000, loss is: [8.212101]\n",
      "epoch_id: 7, batch_id: 43000, loss is: [9.696995]\n",
      "epoch_id: 7, batch_id: 44000, loss is: [16.81592]\n",
      "epoch_id: 7, batch_id: 45000, loss is: [1.360024]\n",
      "epoch_id: 7, batch_id: 46000, loss is: [3.4144998]\n",
      "epoch_id: 7, batch_id: 47000, loss is: [24.643835]\n",
      "epoch_id: 7, batch_id: 48000, loss is: [3.8581717]\n",
      "epoch_id: 7, batch_id: 49000, loss is: [3.9110548]\n",
      "epoch_id: 7, batch_id: 50000, loss is: [15.882122]\n",
      "epoch_id: 7, batch_id: 51000, loss is: [14.528202]\n",
      "epoch_id: 7, batch_id: 52000, loss is: [1.260627]\n",
      "epoch_id: 7, batch_id: 53000, loss is: [9.273533]\n",
      "epoch_id: 7, batch_id: 54000, loss is: [3.086992]\n",
      "epoch_id: 7, batch_id: 55000, loss is: [9.151326]\n",
      "epoch_id: 7, batch_id: 56000, loss is: [3.3930342]\n",
      "epoch_id: 7, batch_id: 57000, loss is: [22.587254]\n",
      "epoch_id: 7, batch_id: 58000, loss is: [0.00372645]\n",
      "epoch_id: 7, batch_id: 59000, loss is: [4.998191]\n",
      "epoch_id: 8, batch_id: 0, loss is: [0.56418926]\n",
      "epoch_id: 8, batch_id: 1000, loss is: [1.3887604]\n",
      "epoch_id: 8, batch_id: 2000, loss is: [16.4873]\n",
      "epoch_id: 8, batch_id: 3000, loss is: [4.5258446]\n",
      "epoch_id: 8, batch_id: 4000, loss is: [1.8206578]\n",
      "epoch_id: 8, batch_id: 5000, loss is: [0.59815097]\n",
      "epoch_id: 8, batch_id: 6000, loss is: [4.2339416]\n",
      "epoch_id: 8, batch_id: 7000, loss is: [3.914057]\n",
      "epoch_id: 8, batch_id: 8000, loss is: [4.7983727]\n",
      "epoch_id: 8, batch_id: 9000, loss is: [4.2510214]\n",
      "epoch_id: 8, batch_id: 10000, loss is: [4.7976356]\n",
      "epoch_id: 8, batch_id: 11000, loss is: [0.06824286]\n",
      "epoch_id: 8, batch_id: 12000, loss is: [0.01078767]\n",
      "epoch_id: 8, batch_id: 13000, loss is: [21.530416]\n",
      "epoch_id: 8, batch_id: 14000, loss is: [16.658184]\n",
      "epoch_id: 8, batch_id: 15000, loss is: [6.900239]\n",
      "epoch_id: 8, batch_id: 16000, loss is: [11.58243]\n",
      "epoch_id: 8, batch_id: 17000, loss is: [10.155548]\n",
      "epoch_id: 8, batch_id: 18000, loss is: [10.090948]\n",
      "epoch_id: 8, batch_id: 19000, loss is: [13.338518]\n",
      "epoch_id: 8, batch_id: 20000, loss is: [5.101316]\n",
      "epoch_id: 8, batch_id: 21000, loss is: [3.7531912]\n",
      "epoch_id: 8, batch_id: 22000, loss is: [14.245877]\n",
      "epoch_id: 8, batch_id: 23000, loss is: [10.440682]\n",
      "epoch_id: 8, batch_id: 24000, loss is: [0.7556889]\n",
      "epoch_id: 8, batch_id: 25000, loss is: [16.961706]\n",
      "epoch_id: 8, batch_id: 26000, loss is: [5.1068316]\n",
      "epoch_id: 8, batch_id: 27000, loss is: [23.092896]\n",
      "epoch_id: 8, batch_id: 28000, loss is: [3.7896338]\n",
      "epoch_id: 8, batch_id: 29000, loss is: [1.2689434]\n",
      "epoch_id: 8, batch_id: 30000, loss is: [8.194644]\n",
      "epoch_id: 8, batch_id: 31000, loss is: [15.902984]\n",
      "epoch_id: 8, batch_id: 32000, loss is: [0.6064403]\n",
      "epoch_id: 8, batch_id: 33000, loss is: [16.691956]\n",
      "epoch_id: 8, batch_id: 34000, loss is: [4.600225e-06]\n",
      "epoch_id: 8, batch_id: 35000, loss is: [17.00989]\n",
      "epoch_id: 8, batch_id: 36000, loss is: [9.527137]\n",
      "epoch_id: 8, batch_id: 37000, loss is: [3.6029334]\n",
      "epoch_id: 8, batch_id: 38000, loss is: [4.5558867]\n",
      "epoch_id: 8, batch_id: 39000, loss is: [0.01073998]\n",
      "epoch_id: 8, batch_id: 40000, loss is: [14.634549]\n",
      "epoch_id: 8, batch_id: 41000, loss is: [23.248102]\n",
      "epoch_id: 8, batch_id: 42000, loss is: [0.656412]\n",
      "epoch_id: 8, batch_id: 43000, loss is: [15.378362]\n",
      "epoch_id: 8, batch_id: 44000, loss is: [4.442664]\n",
      "epoch_id: 8, batch_id: 45000, loss is: [14.648456]\n",
      "epoch_id: 8, batch_id: 46000, loss is: [4.072138]\n",
      "epoch_id: 8, batch_id: 47000, loss is: [1.4413686]\n",
      "epoch_id: 8, batch_id: 48000, loss is: [10.076947]\n",
      "epoch_id: 8, batch_id: 49000, loss is: [25.277264]\n",
      "epoch_id: 8, batch_id: 50000, loss is: [4.372387]\n",
      "epoch_id: 8, batch_id: 51000, loss is: [10.424431]\n",
      "epoch_id: 8, batch_id: 52000, loss is: [14.788402]\n",
      "epoch_id: 8, batch_id: 53000, loss is: [8.988827]\n",
      "epoch_id: 8, batch_id: 54000, loss is: [0.04814512]\n",
      "epoch_id: 8, batch_id: 55000, loss is: [16.245941]\n",
      "epoch_id: 8, batch_id: 56000, loss is: [3.2211523]\n",
      "epoch_id: 8, batch_id: 57000, loss is: [14.404335]\n",
      "epoch_id: 8, batch_id: 58000, loss is: [3.399975]\n",
      "epoch_id: 8, batch_id: 59000, loss is: [7.898013]\n",
      "epoch_id: 9, batch_id: 0, loss is: [3.7203453]\n",
      "epoch_id: 9, batch_id: 1000, loss is: [0.02783068]\n",
      "epoch_id: 9, batch_id: 2000, loss is: [0.657942]\n",
      "epoch_id: 9, batch_id: 3000, loss is: [9.431829]\n",
      "epoch_id: 9, batch_id: 4000, loss is: [4.412225]\n",
      "epoch_id: 9, batch_id: 5000, loss is: [1.4035311]\n",
      "epoch_id: 9, batch_id: 6000, loss is: [4.506346]\n",
      "epoch_id: 9, batch_id: 7000, loss is: [17.503386]\n",
      "epoch_id: 9, batch_id: 8000, loss is: [17.111546]\n",
      "epoch_id: 9, batch_id: 9000, loss is: [23.024244]\n",
      "epoch_id: 9, batch_id: 10000, loss is: [14.214906]\n",
      "epoch_id: 9, batch_id: 11000, loss is: [0.7524004]\n",
      "epoch_id: 9, batch_id: 12000, loss is: [0.04060972]\n",
      "epoch_id: 9, batch_id: 13000, loss is: [17.526327]\n",
      "epoch_id: 9, batch_id: 14000, loss is: [7.8758426]\n",
      "epoch_id: 9, batch_id: 15000, loss is: [7.944015]\n",
      "epoch_id: 9, batch_id: 16000, loss is: [17.184622]\n",
      "epoch_id: 9, batch_id: 17000, loss is: [14.764471]\n",
      "epoch_id: 9, batch_id: 18000, loss is: [16.743593]\n",
      "epoch_id: 9, batch_id: 19000, loss is: [2.0215251]\n",
      "epoch_id: 9, batch_id: 20000, loss is: [1.09499]\n",
      "epoch_id: 9, batch_id: 21000, loss is: [0.61583555]\n",
      "epoch_id: 9, batch_id: 22000, loss is: [1.4936025]\n",
      "epoch_id: 9, batch_id: 23000, loss is: [0.08880875]\n",
      "epoch_id: 9, batch_id: 24000, loss is: [0.04236897]\n",
      "epoch_id: 9, batch_id: 25000, loss is: [17.19459]\n",
      "epoch_id: 9, batch_id: 26000, loss is: [3.3791356]\n",
      "epoch_id: 9, batch_id: 27000, loss is: [0.670663]\n",
      "epoch_id: 9, batch_id: 28000, loss is: [3.3921034]\n",
      "epoch_id: 9, batch_id: 29000, loss is: [3.613328]\n",
      "epoch_id: 9, batch_id: 30000, loss is: [15.926568]\n",
      "epoch_id: 9, batch_id: 31000, loss is: [0.03280788]\n",
      "epoch_id: 9, batch_id: 32000, loss is: [4.395524]\n",
      "epoch_id: 9, batch_id: 33000, loss is: [22.735834]\n",
      "epoch_id: 9, batch_id: 34000, loss is: [13.783489]\n",
      "epoch_id: 9, batch_id: 35000, loss is: [1.3978876]\n",
      "epoch_id: 9, batch_id: 36000, loss is: [1.496933]\n",
      "epoch_id: 9, batch_id: 37000, loss is: [9.948497]\n",
      "epoch_id: 9, batch_id: 38000, loss is: [3.2582533]\n",
      "epoch_id: 9, batch_id: 39000, loss is: [1.1974514]\n",
      "epoch_id: 9, batch_id: 40000, loss is: [1.155519]\n",
      "epoch_id: 9, batch_id: 41000, loss is: [14.760891]\n",
      "epoch_id: 9, batch_id: 42000, loss is: [9.285193]\n",
      "epoch_id: 9, batch_id: 43000, loss is: [23.919659]\n",
      "epoch_id: 9, batch_id: 44000, loss is: [14.771833]\n",
      "epoch_id: 9, batch_id: 45000, loss is: [17.696737]\n",
      "epoch_id: 9, batch_id: 46000, loss is: [2.919969]\n",
      "epoch_id: 9, batch_id: 47000, loss is: [15.444876]\n",
      "epoch_id: 9, batch_id: 48000, loss is: [0.6537429]\n",
      "epoch_id: 9, batch_id: 49000, loss is: [17.028978]\n",
      "epoch_id: 9, batch_id: 50000, loss is: [17.498802]\n",
      "epoch_id: 9, batch_id: 51000, loss is: [17.981678]\n",
      "epoch_id: 9, batch_id: 52000, loss is: [0.00698363]\n",
      "epoch_id: 9, batch_id: 53000, loss is: [10.277151]\n",
      "epoch_id: 9, batch_id: 54000, loss is: [5.1381483]\n",
      "epoch_id: 9, batch_id: 55000, loss is: [16.811575]\n",
      "epoch_id: 9, batch_id: 56000, loss is: [16.838293]\n",
      "epoch_id: 9, batch_id: 57000, loss is: [1.1251142]\n",
      "epoch_id: 9, batch_id: 58000, loss is: [17.155506]\n",
      "epoch_id: 9, batch_id: 59000, loss is: [15.757699]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def norm_img_2(img):\n",
    "    #print(img)\n",
    "    assert len(img.shape) == 3\n",
    "    batch_size, img_h, img_w = img.shape[0], img.shape[1], img.shape[2]\n",
    "    #img.save(\"mid.jpg\")\n",
    "    #img2 = np.float32(img)\n",
    "    #print(type(img2))\n",
    "    #img2 = cv2.imread(\"mid.jpg\")\n",
    "    img2 = img\n",
    "    img2 = np.squeeze(img2, 0)\n",
    "    img2 = np.uint8(img2)\n",
    "    #print(img2.shape)\n",
    "    #mid = Image.fromarray(img2)\n",
    "    #mid.save(\"mid.png\")\n",
    "    cv2.imwrite(\"mid.png\",img2)\n",
    "    #img2 = cv2.cvtColor(np.asarray(img2), cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(img2, 230, 255, cv2.THRESH_BINARY_INV)#二值化，黑白反转\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)#找到边界\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])#获取边界信息\n",
    "    img = paddle.vision.transforms.crop(img, 26 - y, x, h, w)\n",
    "    #img = paddle.vision.transforms.to_tensor(img)\n",
    "    img = paddle.vision.resize(img,(28,28))\n",
    "    img = img / 255\n",
    "    img = paddle.reshape(img, [batch_size, img_h*img_w])\n",
    "    \n",
    "    return img\n",
    "\n",
    "def train_2(model):\n",
    "    model.train()\n",
    "    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'),\n",
    "    \t\t\t\t\t\t\t\t\tbatch_size=1,\n",
    "                                        shuffle=True)\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #主要修改这里喂进去的图像\n",
    "            images = norm_img_2(data[0]).astype('float32')\n",
    "            labels = data[1].astype('float32')\n",
    "            predicts = model(images)\n",
    "\n",
    "            loss = F.square_error_cost(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 10000 == 0:\n",
    "                print(\"epoch_id: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "def before_train(image):\n",
    "    pass\n",
    "\n",
    "#img = load_image(\"test_3_2.jpg\")\n",
    "train_2(model)\n",
    "\n",
    "#train(model)\n",
    "#paddle.save(model.state_dict(), './mnist.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d55bb1-433d-4c96-856a-a13891ac5673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T05:10:19.170971Z",
     "iopub.status.busy": "2021-10-01T05:10:19.170321Z",
     "iopub.status.idle": "2021-10-01T05:10:19.203875Z",
     "shell.execute_reply": "2021-10-01T05:10:19.203138Z",
     "shell.execute_reply.started": "2021-10-01T05:10:19.170685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[248 247 249 ... 248 248 248]\n",
      " [249 248 249 ... 247 247 247]\n",
      " [250 248 248 ... 252 252 251]\n",
      " ...\n",
      " [249 249 250 ... 249 248 247]\n",
      " [250 250 250 ... 250 249 248]\n",
      " [251 251 251 ... 251 250 250]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"test_1.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "print(img)\n",
    "cv2.imwrite(\"img.jpg\",img)\n",
    "\n",
    "paddle.save(model.state_dict(), './mnist_2.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "261f71a9-2701-49d1-b0c4-ebb55449382d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T05:11:20.486112Z",
     "iopub.status.busy": "2021-10-01T05:11:20.485714Z",
     "iopub.status.idle": "2021-10-01T05:11:20.528167Z",
     "shell.execute_reply": "2021-10-01T05:11:20.527483Z",
     "shell.execute_reply.started": "2021-10-01T05:11:20.486058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result Tensor(shape=[1, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[-2.62990475]])\n",
      "本次预测的数字是 [[-2]]\n"
     ]
    }
   ],
   "source": [
    "def load_image_2(img_path):\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    img2 = im\n",
    "    img2 = np.squeeze(img2, 0)\n",
    "    img2 = np.uint8(img2)\n",
    "    #print(img2.shape)\n",
    "    #mid = Image.fromarray(img2)\n",
    "    #mid.save(\"mid.png\")\n",
    "    cv2.imwrite(\"mid.png\",img2)\n",
    "    #img2 = cv2.cvtColor(np.asarray(img2), cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(img2, 230, 255, cv2.THRESH_BINARY_INV)#二值化，黑白反转\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)#找到边界\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])#获取边界信息\n",
    "    img = paddle.vision.transforms.crop(img, 26 - y, x, h, w)\n",
    "    #img = paddle.vision.transforms.to_tensor(img)\n",
    "    #im = paddle.vision.resize(im,(28,28))\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "    im = np.array(im).reshape(1, -1).astype(np.float32)\n",
    "    im = 1 - im / 255\n",
    "    return im\n",
    "\n",
    "model = MINST()\n",
    "params_file_path = 'mnist_2.pdparams'\n",
    "img_path = './test_2.jpg'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "result = model(paddle.to_tensor(tensor_img))\n",
    "print('result',result)\n",
    "print(\"本次预测的数字是\", result.numpy().astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777eaf9-a93b-4900-9aa8-ccc3a6959863",
   "metadata": {},
   "source": [
    "增加预处理的结果更加离谱数字是“11“可还行。\n",
    "\n",
    "分析原因：这是在用一套网络分类10个数字，问题仍然是非线性的，如果只判断是或不是，按照经验应该是线性问题。\n",
    "\n",
    "试验结果：经过预处理，这个问题仍然是非线性问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
