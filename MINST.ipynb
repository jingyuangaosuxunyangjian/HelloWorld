{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78a0d12-1ea1-4445-a21a-874121cf19f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T03:00:32.523252Z",
     "iopub.status.busy": "2021-10-01T03:00:32.522737Z",
     "iopub.status.idle": "2021-10-01T03:01:30.237268Z",
     "shell.execute_reply": "2021-10-01T03:01:30.236445Z",
     "shell.execute_reply.started": "2021-10-01T03:00:32.523017Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file /home/aistudio/.cache/paddle/dataset/mnist/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  if isinstance(obj, collections.Iterator):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return list(data) if isinstance(data, collections.MappingView) else data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(1,) [5]\n",
      "epoch_id: 0, batch_id: 0, loss is: [23.91821]\n",
      "epoch_id: 0, batch_id: 1000, loss is: [5.4421573]\n",
      "epoch_id: 0, batch_id: 2000, loss is: [5.604277]\n",
      "epoch_id: 0, batch_id: 3000, loss is: [4.3068132]\n",
      "epoch_id: 1, batch_id: 0, loss is: [1.5292432]\n",
      "epoch_id: 1, batch_id: 1000, loss is: [4.083521]\n",
      "epoch_id: 1, batch_id: 2000, loss is: [5.945808]\n",
      "epoch_id: 1, batch_id: 3000, loss is: [2.9991937]\n",
      "epoch_id: 2, batch_id: 0, loss is: [3.5016472]\n",
      "epoch_id: 2, batch_id: 1000, loss is: [4.9337196]\n",
      "epoch_id: 2, batch_id: 2000, loss is: [2.509003]\n",
      "epoch_id: 2, batch_id: 3000, loss is: [3.6499386]\n",
      "epoch_id: 3, batch_id: 0, loss is: [3.1101327]\n",
      "epoch_id: 3, batch_id: 1000, loss is: [2.2127628]\n",
      "epoch_id: 3, batch_id: 2000, loss is: [4.772833]\n",
      "epoch_id: 3, batch_id: 3000, loss is: [5.3597293]\n",
      "epoch_id: 4, batch_id: 0, loss is: [2.5742831]\n",
      "epoch_id: 4, batch_id: 1000, loss is: [5.1302752]\n",
      "epoch_id: 4, batch_id: 2000, loss is: [1.2930722]\n",
      "epoch_id: 4, batch_id: 3000, loss is: [2.751317]\n",
      "epoch_id: 5, batch_id: 0, loss is: [3.7138264]\n",
      "epoch_id: 5, batch_id: 1000, loss is: [2.5341952]\n",
      "epoch_id: 5, batch_id: 2000, loss is: [1.738895]\n",
      "epoch_id: 5, batch_id: 3000, loss is: [2.6853826]\n",
      "epoch_id: 6, batch_id: 0, loss is: [4.1442733]\n",
      "epoch_id: 6, batch_id: 1000, loss is: [3.5989842]\n",
      "epoch_id: 6, batch_id: 2000, loss is: [3.9393523]\n",
      "epoch_id: 6, batch_id: 3000, loss is: [7.383123]\n",
      "epoch_id: 7, batch_id: 0, loss is: [2.4403186]\n",
      "epoch_id: 7, batch_id: 1000, loss is: [0.8306954]\n",
      "epoch_id: 7, batch_id: 2000, loss is: [3.714539]\n",
      "epoch_id: 7, batch_id: 3000, loss is: [3.730723]\n",
      "epoch_id: 8, batch_id: 0, loss is: [2.2588744]\n",
      "epoch_id: 8, batch_id: 1000, loss is: [3.3174946]\n",
      "epoch_id: 8, batch_id: 2000, loss is: [4.243886]\n",
      "epoch_id: 8, batch_id: 3000, loss is: [2.410007]\n",
      "epoch_id: 9, batch_id: 0, loss is: [2.6788406]\n",
      "epoch_id: 9, batch_id: 1000, loss is: [2.0992427]\n",
      "epoch_id: 9, batch_id: 2000, loss is: [2.923632]\n",
      "epoch_id: 9, batch_id: 3000, loss is: [2.6558633]\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddle.nn import Linear\n",
    "import paddle.nn.functional as F \n",
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "train_dataset = paddle.vision.MNIST(mode='train')\n",
    "\n",
    "train_data0 = np.array(train_dataset[0][0])\n",
    "train_label_0 = np.array(train_dataset[0][1])\n",
    "plt.figure(\"image\")\n",
    "plt.figure(figsize = (2,2))\n",
    "plt.imshow(train_data0, cmap=plt.cm.binary)\n",
    "plt.axis('on')\n",
    "plt.title('image')\n",
    "plt.show()\n",
    "\n",
    "print(train_data0.shape)\n",
    "print(train_label_0.shape, train_label_0)\n",
    "\n",
    "class MINST(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MINST, self).__init__()\n",
    "\n",
    "        self.fc = paddle.nn.Linear(in_features=784, out_features=1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.fc(inputs)\n",
    "        return outputs\n",
    "\n",
    "def norm_img(img):\n",
    "    assert len(img.shape) == 3\n",
    "    batch_size, img_h, img_w = img.shape[0], img.shape[1], img.shape[2]\n",
    "    img = img / 255\n",
    "    img = paddle.reshape(img, [batch_size, img_h*img_w])\n",
    "    \n",
    "    return img\n",
    "\n",
    "paddle.vision.set_image_backend('cv2')\n",
    "model = MINST()\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'),\n",
    "    \t\t\t\t\t\t\t\t\tbatch_size=16,\n",
    "                                        shuffle=True)\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            images = norm_img(data[0]).astype('float32')\n",
    "            labels = data[1].astype('float32')\n",
    "\n",
    "            predicts = model(images)\n",
    "\n",
    "            loss = F.square_error_cost(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 1000 == 0:\n",
    "                print(\"epoch_id: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "train(model)\n",
    "paddle.save(model.state_dict(), './mnist.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8924008-ae1a-4029-afdd-88326a5cc287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T03:01:34.287193Z",
     "iopub.status.busy": "2021-10-01T03:01:34.286849Z",
     "iopub.status.idle": "2021-10-01T03:01:34.320800Z",
     "shell.execute_reply": "2021-10-01T03:01:34.320017Z",
     "shell.execute_reply.started": "2021-10-01T03:01:34.287143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result Tensor(shape=[1, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[5.62745380]])\n",
      "本次预测的数字是 [[5]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "\n",
    "def load_image(img_path):\n",
    "    im = Image.open(img_path).convert('L')\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\n",
    "    im = np.array(im).reshape(1, -1).astype(np.float32)\n",
    "    im = 1 - im / 255\n",
    "    return im\n",
    "\n",
    "model = MINST()\n",
    "params_file_path = 'mnist.pdparams'\n",
    "img_path = './test_3_2.jpg'\n",
    "param_dict = paddle.load(params_file_path)\n",
    "model.load_dict(param_dict)\n",
    "model.eval()\n",
    "tensor_img = load_image(img_path)\n",
    "result = model(paddle.to_tensor(tensor_img))\n",
    "print('result',result)\n",
    "print(\"本次预测的数字是\", result.numpy().astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8827c4c-00c2-4b5a-91e3-db1d62304847",
   "metadata": {},
   "source": [
    "上面的代码抄自PaddlePaddle的官方教程，注释我懒得写了，去官网找吧\n",
    "\n",
    "这种方式没有经过预处理，直接接入网络，效果实在感人，我写了四个数字，没有一个识别对的，下面分析一下原因。\n",
    "\n",
    "首先，这个问题并不是一个线性的问题，而我们的网络是一个单层的，也就是线性分类器，我们再用一个线性的东西去拟合一个非线性的，所以效果就会很不好。\n",
    "\n",
    "下面对解决方案提出一些解决方案的猜想\n",
    "- 进行预处理，让问题趋近于线性问题\n",
    "- 增加网络的复杂度，去拟合非线性的问题\n",
    "- 先提取特征再进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcaf0d7-c908-48d0-aebb-355cc926f77a",
   "metadata": {},
   "source": [
    "我们先尝试预处理的方案，这里需要在喂数据前进行预处理，我们对训练函数进行修改，并增加预处理函数before_train，需要opencv环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33759a94-77f9-48a1-a13b-6b5d2008f223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T03:17:33.084762Z",
     "iopub.status.busy": "2021-10-01T03:17:33.084220Z",
     "iopub.status.idle": "2021-10-01T03:32:53.911871Z",
     "shell.execute_reply": "2021-10-01T03:32:53.911089Z",
     "shell.execute_reply.started": "2021-10-01T03:17:33.084507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id: 0, batch_id: 0, loss is: [4.5727916]\n",
      "epoch_id: 0, batch_id: 1000, loss is: [4.1569395]\n",
      "epoch_id: 0, batch_id: 2000, loss is: [2.7690372]\n",
      "epoch_id: 0, batch_id: 3000, loss is: [0.25387466]\n",
      "epoch_id: 0, batch_id: 4000, loss is: [17.40837]\n",
      "epoch_id: 0, batch_id: 5000, loss is: [1.0607526]\n",
      "epoch_id: 0, batch_id: 6000, loss is: [0.02257347]\n",
      "epoch_id: 0, batch_id: 7000, loss is: [2.072022]\n",
      "epoch_id: 0, batch_id: 8000, loss is: [1.6369348]\n",
      "epoch_id: 0, batch_id: 9000, loss is: [0.99506795]\n",
      "epoch_id: 0, batch_id: 10000, loss is: [1.2273772]\n",
      "epoch_id: 0, batch_id: 11000, loss is: [6.336706]\n",
      "epoch_id: 0, batch_id: 12000, loss is: [17.914787]\n",
      "epoch_id: 0, batch_id: 13000, loss is: [20.486635]\n",
      "epoch_id: 0, batch_id: 14000, loss is: [0.85344076]\n",
      "epoch_id: 0, batch_id: 15000, loss is: [8.725761]\n",
      "epoch_id: 0, batch_id: 16000, loss is: [15.007486]\n",
      "epoch_id: 0, batch_id: 17000, loss is: [15.629938]\n",
      "epoch_id: 0, batch_id: 18000, loss is: [8.556295]\n",
      "epoch_id: 0, batch_id: 19000, loss is: [1.8699085]\n",
      "epoch_id: 0, batch_id: 20000, loss is: [6.661009]\n",
      "epoch_id: 0, batch_id: 21000, loss is: [7.779697]\n",
      "epoch_id: 0, batch_id: 22000, loss is: [14.223835]\n",
      "epoch_id: 0, batch_id: 23000, loss is: [5.775621]\n",
      "epoch_id: 0, batch_id: 24000, loss is: [0.00161246]\n",
      "epoch_id: 0, batch_id: 25000, loss is: [1.9567165]\n",
      "epoch_id: 0, batch_id: 26000, loss is: [3.0778635]\n",
      "epoch_id: 0, batch_id: 27000, loss is: [3.502357]\n",
      "epoch_id: 0, batch_id: 28000, loss is: [12.151233]\n",
      "epoch_id: 0, batch_id: 29000, loss is: [3.5622036]\n",
      "epoch_id: 0, batch_id: 30000, loss is: [0.58504826]\n",
      "epoch_id: 0, batch_id: 31000, loss is: [10.607872]\n",
      "epoch_id: 0, batch_id: 32000, loss is: [13.611731]\n",
      "epoch_id: 0, batch_id: 33000, loss is: [3.3157966]\n",
      "epoch_id: 0, batch_id: 34000, loss is: [3.699856]\n",
      "epoch_id: 0, batch_id: 35000, loss is: [0.02795954]\n",
      "epoch_id: 0, batch_id: 36000, loss is: [7.636375]\n",
      "epoch_id: 0, batch_id: 37000, loss is: [0.04030319]\n",
      "epoch_id: 0, batch_id: 38000, loss is: [1.8986745]\n",
      "epoch_id: 0, batch_id: 39000, loss is: [0.56158376]\n",
      "epoch_id: 0, batch_id: 40000, loss is: [3.2160606]\n",
      "epoch_id: 0, batch_id: 41000, loss is: [14.8658085]\n",
      "epoch_id: 0, batch_id: 42000, loss is: [9.200071]\n",
      "epoch_id: 0, batch_id: 43000, loss is: [0.29623532]\n",
      "epoch_id: 0, batch_id: 44000, loss is: [6.360019]\n",
      "epoch_id: 0, batch_id: 45000, loss is: [2.1669204]\n",
      "epoch_id: 0, batch_id: 46000, loss is: [0.90302974]\n",
      "epoch_id: 0, batch_id: 47000, loss is: [1.1958551]\n",
      "epoch_id: 0, batch_id: 48000, loss is: [21.96364]\n",
      "epoch_id: 0, batch_id: 49000, loss is: [6.391053]\n",
      "epoch_id: 0, batch_id: 50000, loss is: [23.195137]\n",
      "epoch_id: 0, batch_id: 51000, loss is: [1.2791449]\n",
      "epoch_id: 0, batch_id: 52000, loss is: [0.12613235]\n",
      "epoch_id: 0, batch_id: 53000, loss is: [14.695038]\n",
      "epoch_id: 0, batch_id: 54000, loss is: [25.088116]\n",
      "epoch_id: 0, batch_id: 55000, loss is: [0.00117099]\n",
      "epoch_id: 0, batch_id: 56000, loss is: [3.2474]\n",
      "epoch_id: 0, batch_id: 57000, loss is: [2.7087758]\n",
      "epoch_id: 0, batch_id: 58000, loss is: [1.8571774]\n",
      "epoch_id: 0, batch_id: 59000, loss is: [1.092066]\n",
      "epoch_id: 1, batch_id: 0, loss is: [11.415886]\n",
      "epoch_id: 1, batch_id: 1000, loss is: [4.3367696]\n",
      "epoch_id: 1, batch_id: 2000, loss is: [13.037383]\n",
      "epoch_id: 1, batch_id: 3000, loss is: [10.925615]\n",
      "epoch_id: 1, batch_id: 4000, loss is: [1.3080293]\n",
      "epoch_id: 1, batch_id: 5000, loss is: [0.4856668]\n",
      "epoch_id: 1, batch_id: 6000, loss is: [0.01189768]\n",
      "epoch_id: 1, batch_id: 7000, loss is: [24.140953]\n",
      "epoch_id: 1, batch_id: 8000, loss is: [12.556227]\n",
      "epoch_id: 1, batch_id: 9000, loss is: [1.7533659]\n",
      "epoch_id: 1, batch_id: 10000, loss is: [10.665328]\n",
      "epoch_id: 1, batch_id: 11000, loss is: [1.0181725]\n",
      "epoch_id: 1, batch_id: 12000, loss is: [11.327364]\n",
      "epoch_id: 1, batch_id: 13000, loss is: [0.77284086]\n",
      "epoch_id: 1, batch_id: 14000, loss is: [2.3775349]\n",
      "epoch_id: 1, batch_id: 15000, loss is: [0.9071879]\n",
      "epoch_id: 1, batch_id: 16000, loss is: [16.15519]\n",
      "epoch_id: 1, batch_id: 17000, loss is: [0.5166722]\n",
      "epoch_id: 1, batch_id: 18000, loss is: [5.2414436]\n",
      "epoch_id: 1, batch_id: 19000, loss is: [0.92161566]\n",
      "epoch_id: 1, batch_id: 20000, loss is: [18.632244]\n",
      "epoch_id: 1, batch_id: 21000, loss is: [2.4054756]\n",
      "epoch_id: 1, batch_id: 22000, loss is: [3.4460492]\n",
      "epoch_id: 1, batch_id: 23000, loss is: [0.9425034]\n",
      "epoch_id: 1, batch_id: 24000, loss is: [1.2626431]\n",
      "epoch_id: 1, batch_id: 25000, loss is: [3.2881126]\n",
      "epoch_id: 1, batch_id: 26000, loss is: [7.978288]\n",
      "epoch_id: 1, batch_id: 27000, loss is: [0.7344729]\n",
      "epoch_id: 1, batch_id: 28000, loss is: [10.485857]\n",
      "epoch_id: 1, batch_id: 29000, loss is: [11.626545]\n",
      "epoch_id: 1, batch_id: 30000, loss is: [25.57477]\n",
      "epoch_id: 1, batch_id: 31000, loss is: [9.600969]\n",
      "epoch_id: 1, batch_id: 32000, loss is: [10.0637045]\n",
      "epoch_id: 1, batch_id: 33000, loss is: [0.18235469]\n",
      "epoch_id: 1, batch_id: 34000, loss is: [3.9730034]\n",
      "epoch_id: 1, batch_id: 35000, loss is: [1.2850722]\n",
      "epoch_id: 1, batch_id: 36000, loss is: [10.847849]\n",
      "epoch_id: 1, batch_id: 37000, loss is: [27.327723]\n",
      "epoch_id: 1, batch_id: 38000, loss is: [0.828032]\n",
      "epoch_id: 1, batch_id: 39000, loss is: [0.00560253]\n",
      "epoch_id: 1, batch_id: 40000, loss is: [0.30511692]\n",
      "epoch_id: 1, batch_id: 41000, loss is: [9.305466]\n",
      "epoch_id: 1, batch_id: 42000, loss is: [12.961527]\n",
      "epoch_id: 1, batch_id: 43000, loss is: [10.369783]\n",
      "epoch_id: 1, batch_id: 44000, loss is: [9.818375]\n",
      "epoch_id: 1, batch_id: 45000, loss is: [15.310125]\n",
      "epoch_id: 1, batch_id: 46000, loss is: [1.1380106]\n",
      "epoch_id: 1, batch_id: 47000, loss is: [12.068838]\n",
      "epoch_id: 1, batch_id: 48000, loss is: [0.03384565]\n",
      "epoch_id: 1, batch_id: 49000, loss is: [1.4181687]\n",
      "epoch_id: 1, batch_id: 50000, loss is: [10.081223]\n",
      "epoch_id: 1, batch_id: 51000, loss is: [15.782981]\n",
      "epoch_id: 1, batch_id: 52000, loss is: [3.1670818]\n",
      "epoch_id: 1, batch_id: 53000, loss is: [7.1205635]\n",
      "epoch_id: 1, batch_id: 54000, loss is: [1.1409312]\n",
      "epoch_id: 1, batch_id: 55000, loss is: [0.00015696]\n",
      "epoch_id: 1, batch_id: 56000, loss is: [16.21542]\n",
      "epoch_id: 1, batch_id: 57000, loss is: [23.92896]\n",
      "epoch_id: 1, batch_id: 58000, loss is: [0.01638529]\n",
      "epoch_id: 1, batch_id: 59000, loss is: [1.3477533]\n",
      "epoch_id: 2, batch_id: 0, loss is: [1.4324781]\n",
      "epoch_id: 2, batch_id: 1000, loss is: [29.880968]\n",
      "epoch_id: 2, batch_id: 2000, loss is: [16.766459]\n",
      "epoch_id: 2, batch_id: 3000, loss is: [17.251245]\n",
      "epoch_id: 2, batch_id: 4000, loss is: [3.5541418]\n",
      "epoch_id: 2, batch_id: 5000, loss is: [7.1262984]\n",
      "epoch_id: 2, batch_id: 6000, loss is: [1.431241]\n",
      "epoch_id: 2, batch_id: 7000, loss is: [9.97685]\n",
      "epoch_id: 2, batch_id: 8000, loss is: [1.6035204]\n",
      "epoch_id: 2, batch_id: 9000, loss is: [2.3584926]\n",
      "epoch_id: 2, batch_id: 10000, loss is: [2.93248]\n",
      "epoch_id: 2, batch_id: 11000, loss is: [32.12593]\n",
      "epoch_id: 2, batch_id: 12000, loss is: [3.6403275]\n",
      "epoch_id: 2, batch_id: 13000, loss is: [18.976007]\n",
      "epoch_id: 2, batch_id: 14000, loss is: [11.536275]\n",
      "epoch_id: 2, batch_id: 15000, loss is: [3.7694895]\n",
      "epoch_id: 2, batch_id: 16000, loss is: [14.267138]\n",
      "epoch_id: 2, batch_id: 17000, loss is: [0.24058507]\n",
      "epoch_id: 2, batch_id: 18000, loss is: [1.1991968]\n",
      "epoch_id: 2, batch_id: 19000, loss is: [3.66206]\n",
      "epoch_id: 2, batch_id: 20000, loss is: [0.06044109]\n",
      "epoch_id: 2, batch_id: 21000, loss is: [16.364521]\n",
      "epoch_id: 2, batch_id: 22000, loss is: [0.02666799]\n",
      "epoch_id: 2, batch_id: 23000, loss is: [0.05911995]\n",
      "epoch_id: 2, batch_id: 24000, loss is: [0.9194983]\n",
      "epoch_id: 2, batch_id: 25000, loss is: [3.8933086]\n",
      "epoch_id: 2, batch_id: 26000, loss is: [0.00421912]\n",
      "epoch_id: 2, batch_id: 27000, loss is: [8.144088]\n",
      "epoch_id: 2, batch_id: 28000, loss is: [51.142788]\n",
      "epoch_id: 2, batch_id: 29000, loss is: [7.633629]\n",
      "epoch_id: 2, batch_id: 30000, loss is: [3.5880482]\n",
      "epoch_id: 2, batch_id: 31000, loss is: [15.12655]\n",
      "epoch_id: 2, batch_id: 32000, loss is: [14.737391]\n",
      "epoch_id: 2, batch_id: 33000, loss is: [2.3598344]\n",
      "epoch_id: 2, batch_id: 34000, loss is: [15.035269]\n",
      "epoch_id: 2, batch_id: 35000, loss is: [4.3134475]\n",
      "epoch_id: 2, batch_id: 36000, loss is: [0.70180583]\n",
      "epoch_id: 2, batch_id: 37000, loss is: [4.279462]\n",
      "epoch_id: 2, batch_id: 38000, loss is: [5.264852]\n",
      "epoch_id: 2, batch_id: 39000, loss is: [1.1291019]\n",
      "epoch_id: 2, batch_id: 40000, loss is: [21.090525]\n",
      "epoch_id: 2, batch_id: 41000, loss is: [7.3070316]\n",
      "epoch_id: 2, batch_id: 42000, loss is: [23.62692]\n",
      "epoch_id: 2, batch_id: 43000, loss is: [3.7565637]\n",
      "epoch_id: 2, batch_id: 44000, loss is: [7.2845745]\n",
      "epoch_id: 2, batch_id: 45000, loss is: [0.8601868]\n",
      "epoch_id: 2, batch_id: 46000, loss is: [5.741572]\n",
      "epoch_id: 2, batch_id: 47000, loss is: [20.062279]\n",
      "epoch_id: 2, batch_id: 48000, loss is: [2.948889]\n",
      "epoch_id: 2, batch_id: 49000, loss is: [0.23401994]\n",
      "epoch_id: 2, batch_id: 50000, loss is: [12.69198]\n",
      "epoch_id: 2, batch_id: 51000, loss is: [0.04977816]\n",
      "epoch_id: 2, batch_id: 52000, loss is: [6.5613365]\n",
      "epoch_id: 2, batch_id: 53000, loss is: [0.8002855]\n",
      "epoch_id: 2, batch_id: 54000, loss is: [0.45830745]\n",
      "epoch_id: 2, batch_id: 55000, loss is: [0.69720274]\n",
      "epoch_id: 2, batch_id: 56000, loss is: [4.008406]\n",
      "epoch_id: 2, batch_id: 57000, loss is: [0.19679]\n",
      "epoch_id: 2, batch_id: 58000, loss is: [0.04329126]\n",
      "epoch_id: 2, batch_id: 59000, loss is: [14.90019]\n",
      "epoch_id: 3, batch_id: 0, loss is: [5.648104]\n",
      "epoch_id: 3, batch_id: 1000, loss is: [3.7206984]\n",
      "epoch_id: 3, batch_id: 2000, loss is: [0.2748551]\n",
      "epoch_id: 3, batch_id: 3000, loss is: [1.6399475]\n",
      "epoch_id: 3, batch_id: 4000, loss is: [40.605473]\n",
      "epoch_id: 3, batch_id: 5000, loss is: [2.4292145]\n",
      "epoch_id: 3, batch_id: 6000, loss is: [8.044035]\n",
      "epoch_id: 3, batch_id: 7000, loss is: [3.2642655]\n",
      "epoch_id: 3, batch_id: 8000, loss is: [5.64653]\n",
      "epoch_id: 3, batch_id: 9000, loss is: [0.32902113]\n",
      "epoch_id: 3, batch_id: 10000, loss is: [14.088268]\n",
      "epoch_id: 3, batch_id: 11000, loss is: [8.2589445]\n",
      "epoch_id: 3, batch_id: 12000, loss is: [11.754045]\n",
      "epoch_id: 3, batch_id: 13000, loss is: [4.9326396]\n",
      "epoch_id: 3, batch_id: 14000, loss is: [1.4415827]\n",
      "epoch_id: 3, batch_id: 15000, loss is: [0.49688035]\n",
      "epoch_id: 3, batch_id: 16000, loss is: [6.428266]\n",
      "epoch_id: 3, batch_id: 17000, loss is: [10.024247]\n",
      "epoch_id: 3, batch_id: 18000, loss is: [1.0276815]\n",
      "epoch_id: 3, batch_id: 19000, loss is: [13.333914]\n",
      "epoch_id: 3, batch_id: 20000, loss is: [2.859423]\n",
      "epoch_id: 3, batch_id: 21000, loss is: [2.0926874]\n",
      "epoch_id: 3, batch_id: 22000, loss is: [3.6462252]\n",
      "epoch_id: 3, batch_id: 23000, loss is: [14.533804]\n",
      "epoch_id: 3, batch_id: 24000, loss is: [5.1776977]\n",
      "epoch_id: 3, batch_id: 25000, loss is: [4.7581387e-05]\n",
      "epoch_id: 3, batch_id: 26000, loss is: [13.981428]\n",
      "epoch_id: 3, batch_id: 27000, loss is: [5.316566]\n",
      "epoch_id: 3, batch_id: 28000, loss is: [1.0741879]\n",
      "epoch_id: 3, batch_id: 29000, loss is: [13.1831255]\n",
      "epoch_id: 3, batch_id: 30000, loss is: [7.410759]\n",
      "epoch_id: 3, batch_id: 31000, loss is: [10.468703]\n",
      "epoch_id: 3, batch_id: 32000, loss is: [7.795966]\n",
      "epoch_id: 3, batch_id: 33000, loss is: [15.996307]\n",
      "epoch_id: 3, batch_id: 34000, loss is: [0.18485269]\n",
      "epoch_id: 3, batch_id: 35000, loss is: [5.579902]\n",
      "epoch_id: 3, batch_id: 36000, loss is: [0.46589038]\n",
      "epoch_id: 3, batch_id: 37000, loss is: [1.8450171]\n",
      "epoch_id: 3, batch_id: 38000, loss is: [17.99986]\n",
      "epoch_id: 3, batch_id: 39000, loss is: [0.2649818]\n",
      "epoch_id: 3, batch_id: 40000, loss is: [3.0132458]\n",
      "epoch_id: 3, batch_id: 41000, loss is: [29.686316]\n",
      "epoch_id: 3, batch_id: 42000, loss is: [2.7915668]\n",
      "epoch_id: 3, batch_id: 43000, loss is: [8.913361]\n",
      "epoch_id: 3, batch_id: 44000, loss is: [4.4733553]\n",
      "epoch_id: 3, batch_id: 45000, loss is: [1.5116006]\n",
      "epoch_id: 3, batch_id: 46000, loss is: [0.9480537]\n",
      "epoch_id: 3, batch_id: 47000, loss is: [5.6366982]\n",
      "epoch_id: 3, batch_id: 48000, loss is: [4.4495683]\n",
      "epoch_id: 3, batch_id: 49000, loss is: [12.007177]\n",
      "epoch_id: 3, batch_id: 50000, loss is: [0.8710818]\n",
      "epoch_id: 3, batch_id: 51000, loss is: [0.8457124]\n",
      "epoch_id: 3, batch_id: 52000, loss is: [0.912514]\n",
      "epoch_id: 3, batch_id: 53000, loss is: [9.482164]\n",
      "epoch_id: 3, batch_id: 54000, loss is: [1.3760215]\n",
      "epoch_id: 3, batch_id: 55000, loss is: [0.62209976]\n",
      "epoch_id: 3, batch_id: 56000, loss is: [0.15295188]\n",
      "epoch_id: 3, batch_id: 57000, loss is: [1.8286971]\n",
      "epoch_id: 3, batch_id: 58000, loss is: [4.5655]\n",
      "epoch_id: 3, batch_id: 59000, loss is: [2.4583185]\n",
      "epoch_id: 4, batch_id: 0, loss is: [0.44952843]\n",
      "epoch_id: 4, batch_id: 1000, loss is: [4.631399]\n",
      "epoch_id: 4, batch_id: 2000, loss is: [0.01449385]\n",
      "epoch_id: 4, batch_id: 3000, loss is: [1.2395713]\n",
      "epoch_id: 4, batch_id: 4000, loss is: [3.7312834]\n",
      "epoch_id: 4, batch_id: 5000, loss is: [11.770729]\n",
      "epoch_id: 4, batch_id: 6000, loss is: [1.4816322]\n",
      "epoch_id: 4, batch_id: 7000, loss is: [1.6560823]\n",
      "epoch_id: 4, batch_id: 8000, loss is: [1.52963]\n",
      "epoch_id: 4, batch_id: 9000, loss is: [2.9147363]\n",
      "epoch_id: 4, batch_id: 10000, loss is: [10.38248]\n",
      "epoch_id: 4, batch_id: 11000, loss is: [5.9707646]\n",
      "epoch_id: 4, batch_id: 12000, loss is: [3.4448147]\n",
      "epoch_id: 4, batch_id: 13000, loss is: [1.5659363]\n",
      "epoch_id: 4, batch_id: 14000, loss is: [3.2989922]\n",
      "epoch_id: 4, batch_id: 15000, loss is: [1.3861835]\n",
      "epoch_id: 4, batch_id: 16000, loss is: [3.1978755]\n",
      "epoch_id: 4, batch_id: 17000, loss is: [3.839435]\n",
      "epoch_id: 4, batch_id: 18000, loss is: [8.114907]\n",
      "epoch_id: 4, batch_id: 19000, loss is: [0.19668382]\n",
      "epoch_id: 4, batch_id: 20000, loss is: [5.561024]\n",
      "epoch_id: 4, batch_id: 21000, loss is: [3.744808]\n",
      "epoch_id: 4, batch_id: 22000, loss is: [2.096987]\n",
      "epoch_id: 4, batch_id: 23000, loss is: [16.562737]\n",
      "epoch_id: 4, batch_id: 24000, loss is: [0.83611184]\n",
      "epoch_id: 4, batch_id: 25000, loss is: [2.5864272]\n",
      "epoch_id: 4, batch_id: 26000, loss is: [0.01608376]\n",
      "epoch_id: 4, batch_id: 27000, loss is: [2.4494967]\n",
      "epoch_id: 4, batch_id: 28000, loss is: [19.343845]\n",
      "epoch_id: 4, batch_id: 29000, loss is: [17.114584]\n",
      "epoch_id: 4, batch_id: 30000, loss is: [13.332052]\n",
      "epoch_id: 4, batch_id: 31000, loss is: [0.28991684]\n",
      "epoch_id: 4, batch_id: 32000, loss is: [0.67429096]\n",
      "epoch_id: 4, batch_id: 33000, loss is: [15.841201]\n",
      "epoch_id: 4, batch_id: 34000, loss is: [5.092054]\n",
      "epoch_id: 4, batch_id: 35000, loss is: [3.1659296]\n",
      "epoch_id: 4, batch_id: 36000, loss is: [18.67473]\n",
      "epoch_id: 4, batch_id: 37000, loss is: [9.744486]\n",
      "epoch_id: 4, batch_id: 38000, loss is: [1.2961437]\n",
      "epoch_id: 4, batch_id: 39000, loss is: [14.480644]\n",
      "epoch_id: 4, batch_id: 40000, loss is: [4.834812]\n",
      "epoch_id: 4, batch_id: 41000, loss is: [2.5332685]\n",
      "epoch_id: 4, batch_id: 42000, loss is: [7.681583]\n",
      "epoch_id: 4, batch_id: 43000, loss is: [1.4596089]\n",
      "epoch_id: 4, batch_id: 44000, loss is: [0.8482103]\n",
      "epoch_id: 4, batch_id: 45000, loss is: [2.201876]\n",
      "epoch_id: 4, batch_id: 46000, loss is: [7.0395446]\n",
      "epoch_id: 4, batch_id: 47000, loss is: [36.432487]\n",
      "epoch_id: 4, batch_id: 48000, loss is: [18.121805]\n",
      "epoch_id: 4, batch_id: 49000, loss is: [5.9962506]\n",
      "epoch_id: 4, batch_id: 50000, loss is: [3.9829664]\n",
      "epoch_id: 4, batch_id: 51000, loss is: [29.447113]\n",
      "epoch_id: 4, batch_id: 52000, loss is: [1.3477035]\n",
      "epoch_id: 4, batch_id: 53000, loss is: [0.16132766]\n",
      "epoch_id: 4, batch_id: 54000, loss is: [6.3226905]\n",
      "epoch_id: 4, batch_id: 55000, loss is: [1.3408436]\n",
      "epoch_id: 4, batch_id: 56000, loss is: [0.50398225]\n",
      "epoch_id: 4, batch_id: 57000, loss is: [12.658452]\n",
      "epoch_id: 4, batch_id: 58000, loss is: [16.039633]\n",
      "epoch_id: 4, batch_id: 59000, loss is: [4.963473]\n",
      "epoch_id: 5, batch_id: 0, loss is: [0.00900432]\n",
      "epoch_id: 5, batch_id: 1000, loss is: [2.13615]\n",
      "epoch_id: 5, batch_id: 2000, loss is: [13.767508]\n",
      "epoch_id: 5, batch_id: 3000, loss is: [2.670387]\n",
      "epoch_id: 5, batch_id: 4000, loss is: [9.867401]\n",
      "epoch_id: 5, batch_id: 5000, loss is: [7.9140515]\n",
      "epoch_id: 5, batch_id: 6000, loss is: [10.513928]\n",
      "epoch_id: 5, batch_id: 7000, loss is: [0.12113556]\n",
      "epoch_id: 5, batch_id: 8000, loss is: [0.51369524]\n",
      "epoch_id: 5, batch_id: 9000, loss is: [0.1623772]\n",
      "epoch_id: 5, batch_id: 10000, loss is: [12.2484045]\n",
      "epoch_id: 5, batch_id: 11000, loss is: [6.9117346]\n",
      "epoch_id: 5, batch_id: 12000, loss is: [21.06389]\n",
      "epoch_id: 5, batch_id: 13000, loss is: [22.658478]\n",
      "epoch_id: 5, batch_id: 14000, loss is: [20.851091]\n",
      "epoch_id: 5, batch_id: 15000, loss is: [3.2938392]\n",
      "epoch_id: 5, batch_id: 16000, loss is: [11.441301]\n",
      "epoch_id: 5, batch_id: 17000, loss is: [1.9007789]\n",
      "epoch_id: 5, batch_id: 18000, loss is: [1.2347906]\n",
      "epoch_id: 5, batch_id: 19000, loss is: [5.194178]\n",
      "epoch_id: 5, batch_id: 20000, loss is: [0.31823117]\n",
      "epoch_id: 5, batch_id: 21000, loss is: [14.321748]\n",
      "epoch_id: 5, batch_id: 22000, loss is: [6.0975237]\n",
      "epoch_id: 5, batch_id: 23000, loss is: [10.526107]\n",
      "epoch_id: 5, batch_id: 24000, loss is: [32.766388]\n",
      "epoch_id: 5, batch_id: 25000, loss is: [1.8158773]\n",
      "epoch_id: 5, batch_id: 26000, loss is: [0.4444366]\n",
      "epoch_id: 5, batch_id: 27000, loss is: [8.090947]\n",
      "epoch_id: 5, batch_id: 28000, loss is: [3.8939843]\n",
      "epoch_id: 5, batch_id: 29000, loss is: [3.8929362]\n",
      "epoch_id: 5, batch_id: 30000, loss is: [1.2117754]\n",
      "epoch_id: 5, batch_id: 31000, loss is: [4.09183]\n",
      "epoch_id: 5, batch_id: 32000, loss is: [2.2026627]\n",
      "epoch_id: 5, batch_id: 33000, loss is: [13.4675255]\n",
      "epoch_id: 5, batch_id: 34000, loss is: [10.943817]\n",
      "epoch_id: 5, batch_id: 35000, loss is: [0.13590473]\n",
      "epoch_id: 5, batch_id: 36000, loss is: [0.00015052]\n",
      "epoch_id: 5, batch_id: 37000, loss is: [1.5679765]\n",
      "epoch_id: 5, batch_id: 38000, loss is: [6.0484853]\n",
      "epoch_id: 5, batch_id: 39000, loss is: [14.982705]\n",
      "epoch_id: 5, batch_id: 40000, loss is: [2.088447]\n",
      "epoch_id: 5, batch_id: 41000, loss is: [11.815902]\n",
      "epoch_id: 5, batch_id: 42000, loss is: [0.74440265]\n",
      "epoch_id: 5, batch_id: 43000, loss is: [15.77091]\n",
      "epoch_id: 5, batch_id: 44000, loss is: [0.97979933]\n",
      "epoch_id: 5, batch_id: 45000, loss is: [5.9936643]\n",
      "epoch_id: 5, batch_id: 46000, loss is: [6.6570983]\n",
      "epoch_id: 5, batch_id: 47000, loss is: [9.118404]\n",
      "epoch_id: 5, batch_id: 48000, loss is: [13.785189]\n",
      "epoch_id: 5, batch_id: 49000, loss is: [8.128934]\n",
      "epoch_id: 5, batch_id: 50000, loss is: [4.4262247]\n",
      "epoch_id: 5, batch_id: 51000, loss is: [1.0880384]\n",
      "epoch_id: 5, batch_id: 52000, loss is: [6.657246]\n",
      "epoch_id: 5, batch_id: 53000, loss is: [0.83103824]\n",
      "epoch_id: 5, batch_id: 54000, loss is: [2.317385]\n",
      "epoch_id: 5, batch_id: 55000, loss is: [14.817458]\n",
      "epoch_id: 5, batch_id: 56000, loss is: [15.502904]\n",
      "epoch_id: 5, batch_id: 57000, loss is: [2.012414]\n",
      "epoch_id: 5, batch_id: 58000, loss is: [2.8000088]\n",
      "epoch_id: 5, batch_id: 59000, loss is: [7.3247504]\n",
      "epoch_id: 6, batch_id: 0, loss is: [4.851517]\n",
      "epoch_id: 6, batch_id: 1000, loss is: [15.710734]\n",
      "epoch_id: 6, batch_id: 2000, loss is: [14.043634]\n",
      "epoch_id: 6, batch_id: 3000, loss is: [15.175178]\n",
      "epoch_id: 6, batch_id: 4000, loss is: [0.66827446]\n",
      "epoch_id: 6, batch_id: 5000, loss is: [1.388285]\n",
      "epoch_id: 6, batch_id: 6000, loss is: [2.0546155]\n",
      "epoch_id: 6, batch_id: 7000, loss is: [15.086529]\n",
      "epoch_id: 6, batch_id: 9000, loss is: [15.708274]\n",
      "epoch_id: 6, batch_id: 10000, loss is: [3.974256]\n",
      "epoch_id: 6, batch_id: 11000, loss is: [12.476621]\n",
      "epoch_id: 6, batch_id: 12000, loss is: [30.586367]\n",
      "epoch_id: 6, batch_id: 13000, loss is: [2.2904274]\n",
      "epoch_id: 6, batch_id: 14000, loss is: [12.930199]\n",
      "epoch_id: 6, batch_id: 15000, loss is: [10.790482]\n",
      "epoch_id: 6, batch_id: 16000, loss is: [13.248848]\n",
      "epoch_id: 6, batch_id: 17000, loss is: [0.7904896]\n",
      "epoch_id: 6, batch_id: 18000, loss is: [10.100723]\n",
      "epoch_id: 6, batch_id: 19000, loss is: [8.575275]\n",
      "epoch_id: 6, batch_id: 20000, loss is: [1.1478677]\n",
      "epoch_id: 6, batch_id: 21000, loss is: [3.1670938]\n",
      "epoch_id: 6, batch_id: 22000, loss is: [1.0396122]\n",
      "epoch_id: 6, batch_id: 23000, loss is: [23.417885]\n",
      "epoch_id: 6, batch_id: 24000, loss is: [8.1353035]\n",
      "epoch_id: 6, batch_id: 25000, loss is: [0.7518959]\n",
      "epoch_id: 6, batch_id: 26000, loss is: [15.185065]\n",
      "epoch_id: 6, batch_id: 27000, loss is: [6.848682]\n",
      "epoch_id: 6, batch_id: 28000, loss is: [8.272851]\n",
      "epoch_id: 6, batch_id: 29000, loss is: [1.9843793]\n",
      "epoch_id: 6, batch_id: 30000, loss is: [6.460626]\n",
      "epoch_id: 6, batch_id: 31000, loss is: [0.0037672]\n",
      "epoch_id: 6, batch_id: 32000, loss is: [3.7776113]\n",
      "epoch_id: 6, batch_id: 33000, loss is: [8.883533]\n",
      "epoch_id: 6, batch_id: 34000, loss is: [12.241961]\n",
      "epoch_id: 6, batch_id: 35000, loss is: [0.5081879]\n",
      "epoch_id: 6, batch_id: 36000, loss is: [5.18598]\n",
      "epoch_id: 6, batch_id: 37000, loss is: [27.55542]\n",
      "epoch_id: 6, batch_id: 38000, loss is: [19.374496]\n",
      "epoch_id: 6, batch_id: 39000, loss is: [6.5546274]\n",
      "epoch_id: 6, batch_id: 40000, loss is: [5.1640525]\n",
      "epoch_id: 6, batch_id: 41000, loss is: [24.559387]\n",
      "epoch_id: 6, batch_id: 42000, loss is: [4.823694]\n",
      "epoch_id: 6, batch_id: 43000, loss is: [4.8304105]\n",
      "epoch_id: 6, batch_id: 44000, loss is: [1.1938964]\n",
      "epoch_id: 6, batch_id: 45000, loss is: [7.483413]\n",
      "epoch_id: 6, batch_id: 46000, loss is: [16.588268]\n",
      "epoch_id: 6, batch_id: 47000, loss is: [0.4928099]\n",
      "epoch_id: 6, batch_id: 48000, loss is: [16.761671]\n",
      "epoch_id: 6, batch_id: 49000, loss is: [2.8839293]\n",
      "epoch_id: 6, batch_id: 50000, loss is: [11.505559]\n",
      "epoch_id: 6, batch_id: 51000, loss is: [0.02577818]\n",
      "epoch_id: 6, batch_id: 52000, loss is: [0.40232137]\n",
      "epoch_id: 6, batch_id: 53000, loss is: [0.63732636]\n",
      "epoch_id: 6, batch_id: 54000, loss is: [1.0249202]\n",
      "epoch_id: 6, batch_id: 55000, loss is: [17.100077]\n",
      "epoch_id: 6, batch_id: 56000, loss is: [8.882628]\n",
      "epoch_id: 6, batch_id: 57000, loss is: [7.959944]\n",
      "epoch_id: 6, batch_id: 58000, loss is: [0.3715634]\n",
      "epoch_id: 6, batch_id: 59000, loss is: [35.235493]\n",
      "epoch_id: 7, batch_id: 0, loss is: [5.154686]\n",
      "epoch_id: 7, batch_id: 1000, loss is: [1.5245788]\n",
      "epoch_id: 7, batch_id: 2000, loss is: [3.642646]\n",
      "epoch_id: 7, batch_id: 3000, loss is: [1.3016129]\n",
      "epoch_id: 7, batch_id: 4000, loss is: [3.0067022]\n",
      "epoch_id: 7, batch_id: 5000, loss is: [14.436353]\n",
      "epoch_id: 7, batch_id: 6000, loss is: [11.139795]\n",
      "epoch_id: 7, batch_id: 7000, loss is: [0.16526152]\n",
      "epoch_id: 7, batch_id: 8000, loss is: [1.1435559]\n",
      "epoch_id: 7, batch_id: 9000, loss is: [0.13665444]\n",
      "epoch_id: 7, batch_id: 10000, loss is: [6.297679]\n",
      "epoch_id: 7, batch_id: 11000, loss is: [3.6564941]\n",
      "epoch_id: 7, batch_id: 12000, loss is: [16.354898]\n",
      "epoch_id: 7, batch_id: 13000, loss is: [20.19399]\n",
      "epoch_id: 7, batch_id: 14000, loss is: [7.9145827]\n",
      "epoch_id: 7, batch_id: 15000, loss is: [10.859257]\n",
      "epoch_id: 7, batch_id: 16000, loss is: [0.64705396]\n",
      "epoch_id: 7, batch_id: 17000, loss is: [5.297821]\n",
      "epoch_id: 7, batch_id: 18000, loss is: [2.3005114]\n",
      "epoch_id: 7, batch_id: 19000, loss is: [9.62197]\n",
      "epoch_id: 7, batch_id: 20000, loss is: [16.07549]\n",
      "epoch_id: 7, batch_id: 21000, loss is: [1.131588]\n",
      "epoch_id: 7, batch_id: 22000, loss is: [0.9966773]\n",
      "epoch_id: 7, batch_id: 23000, loss is: [3.6995902]\n",
      "epoch_id: 7, batch_id: 24000, loss is: [1.9349732]\n",
      "epoch_id: 7, batch_id: 25000, loss is: [0.6447868]\n",
      "epoch_id: 7, batch_id: 26000, loss is: [3.9080284]\n",
      "epoch_id: 7, batch_id: 27000, loss is: [7.5683274]\n",
      "epoch_id: 7, batch_id: 28000, loss is: [6.9947133]\n",
      "epoch_id: 7, batch_id: 29000, loss is: [17.027264]\n",
      "epoch_id: 7, batch_id: 30000, loss is: [0.05126641]\n",
      "epoch_id: 7, batch_id: 31000, loss is: [1.7320104]\n",
      "epoch_id: 7, batch_id: 32000, loss is: [8.580198]\n",
      "epoch_id: 7, batch_id: 34000, loss is: [3.9298103]\n",
      "epoch_id: 7, batch_id: 35000, loss is: [1.2597567]\n",
      "epoch_id: 7, batch_id: 36000, loss is: [1.7434933]\n",
      "epoch_id: 7, batch_id: 37000, loss is: [4.050812]\n",
      "epoch_id: 7, batch_id: 38000, loss is: [2.1053283]\n",
      "epoch_id: 7, batch_id: 39000, loss is: [3.8982537]\n",
      "epoch_id: 7, batch_id: 40000, loss is: [1.2458895]\n",
      "epoch_id: 7, batch_id: 41000, loss is: [0.3921685]\n",
      "epoch_id: 7, batch_id: 42000, loss is: [14.295594]\n",
      "epoch_id: 7, batch_id: 43000, loss is: [37.614494]\n",
      "epoch_id: 7, batch_id: 44000, loss is: [3.5176013]\n",
      "epoch_id: 7, batch_id: 45000, loss is: [9.54572]\n",
      "epoch_id: 7, batch_id: 46000, loss is: [3.6098936]\n",
      "epoch_id: 7, batch_id: 47000, loss is: [4.9753737]\n",
      "epoch_id: 7, batch_id: 48000, loss is: [1.3579094]\n",
      "epoch_id: 7, batch_id: 49000, loss is: [3.91902]\n",
      "epoch_id: 7, batch_id: 50000, loss is: [14.309848]\n",
      "epoch_id: 7, batch_id: 51000, loss is: [10.652214]\n",
      "epoch_id: 7, batch_id: 52000, loss is: [3.0315132]\n",
      "epoch_id: 7, batch_id: 53000, loss is: [0.705573]\n",
      "epoch_id: 7, batch_id: 54000, loss is: [0.03179409]\n",
      "epoch_id: 7, batch_id: 55000, loss is: [14.795811]\n",
      "epoch_id: 7, batch_id: 56000, loss is: [15.774046]\n",
      "epoch_id: 7, batch_id: 57000, loss is: [15.2954235]\n",
      "epoch_id: 7, batch_id: 58000, loss is: [13.207081]\n",
      "epoch_id: 7, batch_id: 59000, loss is: [22.070555]\n",
      "epoch_id: 8, batch_id: 0, loss is: [16.336336]\n",
      "epoch_id: 8, batch_id: 1000, loss is: [1.0982207]\n",
      "epoch_id: 8, batch_id: 2000, loss is: [8.479906]\n",
      "epoch_id: 8, batch_id: 3000, loss is: [1.2048388]\n",
      "epoch_id: 8, batch_id: 4000, loss is: [0.15218043]\n",
      "epoch_id: 8, batch_id: 5000, loss is: [3.5908642]\n",
      "epoch_id: 8, batch_id: 6000, loss is: [3.758855]\n",
      "epoch_id: 8, batch_id: 7000, loss is: [6.4887295]\n",
      "epoch_id: 8, batch_id: 8000, loss is: [2.5321386]\n",
      "epoch_id: 8, batch_id: 9000, loss is: [5.3842793]\n",
      "epoch_id: 8, batch_id: 10000, loss is: [0.97197235]\n",
      "epoch_id: 8, batch_id: 11000, loss is: [16.046152]\n",
      "epoch_id: 8, batch_id: 12000, loss is: [0.36437386]\n",
      "epoch_id: 8, batch_id: 13000, loss is: [3.4051046]\n",
      "epoch_id: 8, batch_id: 14000, loss is: [3.065367]\n",
      "epoch_id: 8, batch_id: 15000, loss is: [4.3385143]\n",
      "epoch_id: 8, batch_id: 16000, loss is: [2.4474301]\n",
      "epoch_id: 8, batch_id: 17000, loss is: [14.926777]\n",
      "epoch_id: 8, batch_id: 18000, loss is: [15.490439]\n",
      "epoch_id: 8, batch_id: 19000, loss is: [0.59571946]\n",
      "epoch_id: 8, batch_id: 20000, loss is: [0.21840979]\n",
      "epoch_id: 8, batch_id: 21000, loss is: [6.580549]\n",
      "epoch_id: 8, batch_id: 22000, loss is: [5.080018]\n",
      "epoch_id: 8, batch_id: 23000, loss is: [3.0569816]\n",
      "epoch_id: 8, batch_id: 24000, loss is: [1.9096208]\n",
      "epoch_id: 8, batch_id: 25000, loss is: [15.162817]\n",
      "epoch_id: 8, batch_id: 26000, loss is: [6.043701]\n",
      "epoch_id: 8, batch_id: 27000, loss is: [15.089055]\n",
      "epoch_id: 8, batch_id: 28000, loss is: [8.338405]\n",
      "epoch_id: 8, batch_id: 29000, loss is: [3.7879503]\n",
      "epoch_id: 8, batch_id: 30000, loss is: [6.8792744]\n",
      "epoch_id: 8, batch_id: 31000, loss is: [8.39062]\n",
      "epoch_id: 8, batch_id: 32000, loss is: [14.550959]\n",
      "epoch_id: 8, batch_id: 33000, loss is: [11.361949]\n",
      "epoch_id: 8, batch_id: 34000, loss is: [17.199205]\n",
      "epoch_id: 8, batch_id: 35000, loss is: [14.040472]\n",
      "epoch_id: 8, batch_id: 36000, loss is: [3.9490008]\n",
      "epoch_id: 8, batch_id: 37000, loss is: [20.391407]\n",
      "epoch_id: 8, batch_id: 38000, loss is: [3.3055031]\n",
      "epoch_id: 8, batch_id: 39000, loss is: [0.60188377]\n",
      "epoch_id: 8, batch_id: 40000, loss is: [0.48784652]\n",
      "epoch_id: 8, batch_id: 41000, loss is: [1.6551092]\n",
      "epoch_id: 8, batch_id: 42000, loss is: [21.232906]\n",
      "epoch_id: 8, batch_id: 43000, loss is: [3.8880332]\n",
      "epoch_id: 8, batch_id: 44000, loss is: [6.0303097]\n",
      "epoch_id: 8, batch_id: 45000, loss is: [0.14179544]\n",
      "epoch_id: 8, batch_id: 46000, loss is: [24.988462]\n",
      "epoch_id: 8, batch_id: 47000, loss is: [18.231266]\n",
      "epoch_id: 8, batch_id: 48000, loss is: [3.0355163]\n",
      "epoch_id: 8, batch_id: 49000, loss is: [0.8859944]\n",
      "epoch_id: 8, batch_id: 50000, loss is: [12.441942]\n",
      "epoch_id: 8, batch_id: 51000, loss is: [7.6170945]\n",
      "epoch_id: 8, batch_id: 52000, loss is: [7.7164607]\n",
      "epoch_id: 8, batch_id: 53000, loss is: [6.1092973]\n",
      "epoch_id: 8, batch_id: 54000, loss is: [17.205814]\n",
      "epoch_id: 8, batch_id: 55000, loss is: [7.382181]\n",
      "epoch_id: 8, batch_id: 56000, loss is: [0.72154605]\n",
      "epoch_id: 8, batch_id: 57000, loss is: [29.23945]\n",
      "epoch_id: 8, batch_id: 58000, loss is: [1.1740899]\n",
      "epoch_id: 8, batch_id: 59000, loss is: [1.1032155]\n",
      "epoch_id: 9, batch_id: 0, loss is: [1.3135234]\n",
      "epoch_id: 9, batch_id: 1000, loss is: [16.23045]\n",
      "epoch_id: 9, batch_id: 2000, loss is: [1.2119917]\n",
      "epoch_id: 9, batch_id: 3000, loss is: [0.55647093]\n",
      "epoch_id: 9, batch_id: 4000, loss is: [25.962112]\n",
      "epoch_id: 9, batch_id: 5000, loss is: [8.287574]\n",
      "epoch_id: 9, batch_id: 6000, loss is: [0.82808846]\n",
      "epoch_id: 9, batch_id: 7000, loss is: [7.8549724]\n",
      "epoch_id: 9, batch_id: 8000, loss is: [9.993285]\n",
      "epoch_id: 9, batch_id: 9000, loss is: [3.2553017]\n",
      "epoch_id: 9, batch_id: 10000, loss is: [6.194803]\n",
      "epoch_id: 9, batch_id: 11000, loss is: [15.158899]\n",
      "epoch_id: 9, batch_id: 12000, loss is: [2.9300752]\n",
      "epoch_id: 9, batch_id: 13000, loss is: [16.705322]\n",
      "epoch_id: 9, batch_id: 14000, loss is: [0.98931605]\n",
      "epoch_id: 9, batch_id: 15000, loss is: [1.2925849]\n",
      "epoch_id: 9, batch_id: 16000, loss is: [17.03545]\n",
      "epoch_id: 9, batch_id: 17000, loss is: [0.534446]\n",
      "epoch_id: 9, batch_id: 18000, loss is: [0.18988264]\n",
      "epoch_id: 9, batch_id: 19000, loss is: [3.3169272]\n",
      "epoch_id: 9, batch_id: 20000, loss is: [15.418401]\n",
      "epoch_id: 9, batch_id: 21000, loss is: [2.8823278]\n",
      "epoch_id: 9, batch_id: 22000, loss is: [1.7639091]\n",
      "epoch_id: 9, batch_id: 23000, loss is: [15.426071]\n",
      "epoch_id: 9, batch_id: 24000, loss is: [0.21884099]\n",
      "epoch_id: 9, batch_id: 25000, loss is: [4.978063]\n",
      "epoch_id: 9, batch_id: 26000, loss is: [0.5628312]\n",
      "epoch_id: 9, batch_id: 27000, loss is: [0.11152613]\n",
      "epoch_id: 9, batch_id: 28000, loss is: [2.1563008]\n",
      "epoch_id: 9, batch_id: 29000, loss is: [1.0677078]\n",
      "epoch_id: 9, batch_id: 30000, loss is: [0.02211148]\n",
      "epoch_id: 9, batch_id: 31000, loss is: [1.6559154]\n",
      "epoch_id: 9, batch_id: 32000, loss is: [15.877368]\n",
      "epoch_id: 9, batch_id: 33000, loss is: [2.6281366]\n",
      "epoch_id: 9, batch_id: 34000, loss is: [4.136114]\n",
      "epoch_id: 9, batch_id: 35000, loss is: [2.824654]\n",
      "epoch_id: 9, batch_id: 36000, loss is: [0.5086326]\n",
      "epoch_id: 9, batch_id: 37000, loss is: [6.460946]\n",
      "epoch_id: 9, batch_id: 38000, loss is: [8.709229]\n",
      "epoch_id: 9, batch_id: 39000, loss is: [16.425165]\n",
      "epoch_id: 9, batch_id: 40000, loss is: [17.223133]\n",
      "epoch_id: 9, batch_id: 41000, loss is: [14.379501]\n",
      "epoch_id: 9, batch_id: 42000, loss is: [4.156504]\n",
      "epoch_id: 9, batch_id: 43000, loss is: [18.07823]\n",
      "epoch_id: 9, batch_id: 44000, loss is: [0.92602646]\n",
      "epoch_id: 9, batch_id: 45000, loss is: [0.0833472]\n",
      "epoch_id: 9, batch_id: 46000, loss is: [1.4874351]\n",
      "epoch_id: 9, batch_id: 47000, loss is: [1.4159877]\n",
      "epoch_id: 9, batch_id: 48000, loss is: [0.3018161]\n",
      "epoch_id: 9, batch_id: 49000, loss is: [2.13713]\n",
      "epoch_id: 9, batch_id: 50000, loss is: [5.730598]\n",
      "epoch_id: 9, batch_id: 51000, loss is: [14.365072]\n",
      "epoch_id: 9, batch_id: 52000, loss is: [13.480824]\n",
      "epoch_id: 9, batch_id: 53000, loss is: [0.06820275]\n",
      "epoch_id: 9, batch_id: 54000, loss is: [40.25425]\n",
      "epoch_id: 9, batch_id: 55000, loss is: [11.912161]\n",
      "epoch_id: 9, batch_id: 56000, loss is: [14.693981]\n",
      "epoch_id: 9, batch_id: 57000, loss is: [0.08722434]\n",
      "epoch_id: 9, batch_id: 58000, loss is: [7.089299]\n",
      "epoch_id: 9, batch_id: 59000, loss is: [10.322078]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def norm_img_2(img):\n",
    "    #print(img)\n",
    "    assert len(img.shape) == 3\n",
    "    batch_size, img_h, img_w = img.shape[0], img.shape[1], img.shape[2]\n",
    "    #img.save(\"mid.jpg\")\n",
    "    #img2 = np.float32(img)\n",
    "    #print(type(img2))\n",
    "    #img2 = cv2.imread(\"mid.jpg\")\n",
    "    img2 = img\n",
    "    img2 = np.squeeze(img2, 0)\n",
    "    img2 = np.uint8(img2)\n",
    "    #print(img2.shape)\n",
    "    #mid = Image.fromarray(img2)\n",
    "    #mid.save(\"mid.png\")\n",
    "    cv2.imwrite(\"mid.png\",img2)\n",
    "    #img2 = cv2.cvtColor(np.asarray(img2), cv2.COLOR_RGB2GRAY)\n",
    "    ret, thresh = cv2.threshold(img2, 230, 255, cv2.THRESH_BINARY_INV)#二值化，黑白反转\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)#找到边界\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])#获取边界信息\n",
    "    img = paddle.vision.transforms.crop(img, 20, 3, 10, 10)\n",
    "    #img = paddle.vision.transforms.to_tensor(img)\n",
    "    img = paddle.vision.resize(img,(28,28))\n",
    "    img = img / 255\n",
    "    img = paddle.reshape(img, [batch_size, img_h*img_w])\n",
    "    \n",
    "    return img\n",
    "\n",
    "def train_2(model):\n",
    "    model.train()\n",
    "    train_loader = paddle.io.DataLoader(paddle.vision.datasets.MNIST(mode='train'),\n",
    "    \t\t\t\t\t\t\t\t\tbatch_size=1,\n",
    "                                        shuffle=True)\n",
    "    opt = paddle.optimizer.SGD(learning_rate=0.001, parameters=model.parameters())\n",
    "    EPOCH_NUM = 10\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #主要修改这里喂进去的图像\n",
    "            images = norm_img_2(data[0]).astype('float32')\n",
    "            labels = data[1].astype('float32')\n",
    "            predicts = model(images)\n",
    "\n",
    "            loss = F.square_error_cost(predicts, labels)\n",
    "            avg_loss = paddle.mean(loss)\n",
    "\n",
    "            if batch_id % 1000 == 0:\n",
    "                print(\"epoch_id: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "\n",
    "            avg_loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "def before_train(image):\n",
    "    pass\n",
    "\n",
    "#img = load_image(\"test_3_2.jpg\")\n",
    "train_2(model)\n",
    "\n",
    "#train(model)\n",
    "#paddle.save(model.state_dict(), './mnist.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d55bb1-433d-4c96-856a-a13891ac5673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T03:34:39.116380Z",
     "iopub.status.busy": "2021-10-01T03:34:39.116022Z",
     "iopub.status.idle": "2021-10-01T03:34:39.147991Z",
     "shell.execute_reply": "2021-10-01T03:34:39.147272Z",
     "shell.execute_reply.started": "2021-10-01T03:34:39.116330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[248 247 249 ... 248 248 248]\n",
      " [249 248 249 ... 247 247 247]\n",
      " [250 248 248 ... 252 252 251]\n",
      " ...\n",
      " [249 249 250 ... 249 248 247]\n",
      " [250 250 250 ... 250 249 248]\n",
      " [251 251 251 ... 251 250 250]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"test_1.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "print(img)\n",
    "cv2.imwrite(\"img.jpg\",img)\n",
    "\n",
    "paddle.save(model.state_dict(), './mnist_2.pdparams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "261f71a9-2701-49d1-b0c4-ebb55449382d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-01T03:35:26.064809Z",
     "iopub.status.busy": "2021-10-01T03:35:26.064454Z",
     "iopub.status.idle": "2021-10-01T03:35:26.105310Z",
     "shell.execute_reply": "2021-10-01T03:35:26.104600Z",
     "shell.execute_reply.started": "2021-10-01T03:35:26.064760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result Tensor(shape=[1, 1], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[11.37663651]])\n",
      "本次预测的数字是 [[11]]\n"
     ]
    }
   ],
   "source": [
    "def load_image_2(img_path):\r\n",
    "    im = Image.open(img_path).convert('L')\r\n",
    "    img2 = im\r\n",
    "    img2 = np.squeeze(img2, 0)\r\n",
    "    img2 = np.uint8(img2)\r\n",
    "    #print(img2.shape)\r\n",
    "    #mid = Image.fromarray(img2)\r\n",
    "    #mid.save(\"mid.png\")\r\n",
    "    cv2.imwrite(\"mid.png\",img2)\r\n",
    "    #img2 = cv2.cvtColor(np.asarray(img2), cv2.COLOR_RGB2GRAY)\r\n",
    "    ret, thresh = cv2.threshold(img2, 230, 255, cv2.THRESH_BINARY_INV)#二值化，黑白反转\r\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)#找到边界\r\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])#获取边界信息\r\n",
    "    img = paddle.vision.transforms.crop(img, 20, 3, 10, 10)\r\n",
    "    #img = paddle.vision.transforms.to_tensor(img)\r\n",
    "    #im = paddle.vision.resize(im,(28,28))\r\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)\r\n",
    "    im = np.array(im).reshape(1, -1).astype(np.float32)\r\n",
    "    im = 1 - im / 255\r\n",
    "    return im\r\n",
    "\r\n",
    "model = MINST()\r\n",
    "params_file_path = 'mnist_2.pdparams'\r\n",
    "img_path = './test_2.jpg'\r\n",
    "param_dict = paddle.load(params_file_path)\r\n",
    "model.load_dict(param_dict)\r\n",
    "model.eval()\r\n",
    "tensor_img = load_image(img_path)\r\n",
    "result = model(paddle.to_tensor(tensor_img))\r\n",
    "print('result',result)\r\n",
    "print(\"本次预测的数字是\", result.numpy().astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2777eaf9-a93b-4900-9aa8-ccc3a6959863",
   "metadata": {},
   "source": [
    "增加预处理的结果更加离谱数字是“11“可还行。\n",
    "\n",
    "分析原因：这是在用一套网络分类10个数字，问题仍然是非线性的，如果只判断是或不是，按照经验应该是线性问题。\n",
    "\n",
    "试验结果：经过预处理，这个问题仍然是非线性问题。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
